<<<<<<< HEAD
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1QiG4zWZdW2uli2gP3kefLb-J6AKcGduq","timestamp":1762917830714},{"file_id":"1QxDB72JWQWjrFlUKwfx_i-f84wGmS87T","timestamp":1762916838842},{"file_id":"https://github.com/pvateekul/2190513_DS-ICE_2025s1/blob/main/code/Week12_GenerativeAI/7_2_LLM_Prompt_Engineering_Basic_LangChain.ipynb","timestamp":1762916612684}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e85183467d2b428fa787422d65410ebf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_11b527e0250749b0bcdb0b00d9b8efa0","IPY_MODEL_94e0e8191ea44af5b84d309b3cee9b80","IPY_MODEL_f5cc9dfc46f248b082dc6784bd8ee47e"],"layout":"IPY_MODEL_64f721c6438647008ad61a13c46306b0"}},"11b527e0250749b0bcdb0b00d9b8efa0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e14386b9c01642ac840e938d18d74cb3","placeholder":"​","style":"IPY_MODEL_38288475755d444b9f59e43fdf15694d","value":"100%"}},"94e0e8191ea44af5b84d309b3cee9b80":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29737e3418824aed9eb519735367d965","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5ba80bf20fe4deca5245a732b0e1406","value":10}},"f5cc9dfc46f248b082dc6784bd8ee47e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c8c84bfa9034f30b3afd1e56eeb2386","placeholder":"​","style":"IPY_MODEL_40fcc477884245628dfc8a0a6fb0e720","value":" 10/10 [00:21&lt;00:00,  2.20s/it]"}},"64f721c6438647008ad61a13c46306b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e14386b9c01642ac840e938d18d74cb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38288475755d444b9f59e43fdf15694d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29737e3418824aed9eb519735367d965":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5ba80bf20fe4deca5245a732b0e1406":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c8c84bfa9034f30b3afd1e56eeb2386":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40fcc477884245628dfc8a0a6fb0e720":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Overall of this notebook"],"metadata":{"id":"VXSQW2RpFSYe"}},{"cell_type":"markdown","source":["Most of concepts and codes are adapted from\n","- https://github.com/dair-ai/Prompt-Engineering-Guide\n","- https://ai.google.dev/gemini-api/docs/prompting-strategies\n","- https://myframework.net/icio-ai-prompt-framework/"],"metadata":{"id":"uwrZRFXNFj74"}},{"cell_type":"markdown","source":["# Setting environments and model setup"],"metadata":{"id":"tXNDggfzh28Q"}},{"cell_type":"code","source":["%%capture\n","!pip install -qU langchain-google-genai"],"metadata":{"id":"ZRhhli6S3UkP","executionInfo":{"status":"ok","timestamp":1762917910779,"user_tz":-420,"elapsed":19285,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Request for Google API KEY here : https://aistudio.google.com/app/apikey"],"metadata":{"id":"3sT4diEh3gUJ"}},{"cell_type":"code","source":["from getpass import getpass\n","import os\n","\n","if \"GOOGLE_API_KEY\" not in os.environ:\n","    os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google AI API key: \")"],"metadata":{"id":"wPsljCqyNPnt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"75a1825a-26ce-44a7-84bb-e584b976695c","executionInfo":{"status":"ok","timestamp":1762917923604,"user_tz":-420,"elapsed":1495,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Google AI API key: ··········\n"]}]},{"cell_type":"code","source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-2.5-flash\",\n","    temperature=0,\n","    max_tokens=None,\n","    timeout=None,\n","    max_retries=2,\n","    # other params...\n",")"],"metadata":{"id":"sbi2CAPqOHef","executionInfo":{"status":"ok","timestamp":1762917938999,"user_tz":-420,"elapsed":11337,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Basic"],"metadata":{"id":"enmt8H4Shngs"}},{"cell_type":"markdown","source":["## System Prompt / User Prompt"],"metadata":{"id":"rF6TFz-mFEK-"}},{"cell_type":"markdown","source":["`System Prompt`:\n","\n","The system prompt establishes the overall context, persona, and behavioral guidelines for the LLM. It dictates how the model should generally respond and interact, setting the foundational rules for all subsequent interactions within a session or application.\n","\n","`User Prompt (Human)`:\n","\n","  The user prompt is the specific query or instruction provided by the user to the LLM. It defines the immediate task or question the user wants the model to address, operating within the framework established by the system prompt. example\n"],"metadata":{"id":"6Xuv336sgo_2"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYdX-hTxE_vg","outputId":"42f408d5-00dc-48c0-f792-f41fabee118f","executionInfo":{"status":"ok","timestamp":1762917407460,"user_tz":-420,"elapsed":3064,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Exercise is fundamental for optimizing physical and mental health, preventing chronic diseases, and enhancing overall quality of life and longevity.\n"]}],"source":["# Demo 1: System - Health Scientist / User - Explain the importance of exercise\n","messages = [\n","    (\"system\", \"You are a health scientist who always provides factual and evidence-based answers.\"),\n","    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n","]\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"]},{"cell_type":"code","source":["# Demo 2: Syetem - Elderly Person Complaining / User - Explain the importance of exercise\n","messages = [\n","    (\"system\", \"You are an elderly person who often complains.\"),\n","    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n","]\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_y6fndhCsxL9","outputId":"342ab8ad-d573-4b70-8919-bf857db95109","executionInfo":{"status":"ok","timestamp":1762917412051,"user_tz":-420,"elapsed":3129,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Oh, it's just so you don't seize up entirely, I suppose. A real bother, if you ask me.\n"]}]},{"cell_type":"code","source":["# Demo 3: System - Mother Explaining to a 5-year-old / User - Explain the importance of exercise\n","messages = [\n","    (\"system\", \"You are a mother who needs to answer questions from a 5-year-old child, always explaining complex topics in the simplest way possible.\"),\n","    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n","]\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2epKy8w5sync","outputId":"f76910eb-486e-4b3a-e026-8184846b27c6","executionInfo":{"status":"ok","timestamp":1762917415606,"user_tz":-420,"elapsed":2127,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Moving your body makes you super strong and gives you lots of energy to play all day!\n"]}]},{"cell_type":"code","source":["# Demo 4: Professional Assistant (Python factorial)\n","messages = [\n","    (\"system\", \"You are a helpful and informative assistant. Your responses should be clear, concise, and professional. Avoid making assumptions and always ask for clarification if a user's request is ambiguous.\"),\n","    (\"human\", \"Write a Python function that calculates the factorial of a given number.\"),\n","]\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lblLbxY2s2An","outputId":"10027269-3c46-487d-d904-1f5cbf76bcf2","executionInfo":{"status":"ok","timestamp":1762917419654,"user_tz":-420,"elapsed":2676,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["```python\n","def calculate_factorial(n):\n","  \"\"\"\n","  Calculates the factorial of a non-negative integer.\n","\n","  Args:\n","    n: An integer for which to calculate the factorial.\n","\n","  Returns:\n","    The factorial of n if n is a non-negative integer.\n","    Returns None and prints an error message if n is negative.\n","  \"\"\"\n","  if not isinstance(n, int):\n","    print(\"Error: Input must be an integer.\")\n","    return None\n","  if n < 0:\n","    print(\"Error: Factorial is not defined for negative numbers.\")\n","    return None\n","  elif n == 0:\n","    return 1\n","  else:\n","    factorial = 1\n","    for i in range(1, n + 1):\n","      factorial *= i\n","    return factorial\n","\n","# Example Usage:\n","if __name__ == \"__main__\":\n","  print(f\"Factorial of 5: {calculate_factorial(5)}\")    # Expected: 120\n","  print(f\"Factorial of 0: {calculate_factorial(0)}\")    # Expected: 1\n","  print(f\"Factorial of 1: {calculate_factorial(1)}\")    # Expected: 1\n","  print(f\"Factorial of 10: {calculate_factorial(10)}\")  # Expected: 3628800\n","  print(f\"Factorial of -3: {calculate_factorial(-3)}\")  # Expected: Error message and None\n","  print(f\"Factorial of 3.5: {calculate_factorial(3.5)}\") # Expected: Error message and None\n","```\n"]}]},{"cell_type":"markdown","source":["## User Prompt Framework - ICIO"],"metadata":{"id":"8PNPxY_VFH5C"}},{"cell_type":"markdown","source":["The ICIO framework is a simple and practical method that **helps you structure your prompts** step by step.\n","- `Instruction (I)` --> What do you want the AI to do?\n","\n","  - The instruction should be specific and direct. A clear task helps the AI give you the right kind of output.\n","- `Context (C)` --> Give background information. Why are you doing this task? What’s the situation?\n","\n","  - Context helps the AI better understand your purpose and tone.\n","  - ***Optional, but nice to have.***\n","\n","- `Input (I)` --> What exact text or data should the AI process?\n","  - Provide the content the AI needs to work with.\n","  - Without input data, the AI may guess or go off track. Be clear and complete.\n","\n","- `Output (O)` --> Set the style or format of the output. What should the response look like? What tone or structure do you expect?\n","  - This helps guide the AI to produce the kind of result you want."],"metadata":{"id":"fMZNMsDQFL2a"}},{"cell_type":"code","source":["# Example A: Customer Feedback Summary\n","\n","# ICIO fields\n","instruction = \"Summarize customer opinions.\"\n","context = \"For the product development team to consider improvements in the next version.\"\n","input_text = (\n","    \"Many customers like the battery lasting up to 3 days, which is much better than the older version. \"\n","    \"The AMOLED screen provides vibrant colors and is clearly visible even under bright sunlight. \"\n","    \"However, some users reported that Bluetooth connections with certain headphones often drop. \"\n","    \"The sleep tracking system is also not very accurate and sometimes fails to record data. \"\n","    \"Additionally, customers would like to see a blood pressure monitoring function added.\"\n",")\n","output_format = 'Summarize into a table with 3 columns: \"Feature\", \"Status (Good/Needs Improvement/Requested)\", \"Notes\".'\n","\n","# Create messages\n","messages = [\n","    (\"system\", \"You are a product analyst who summarizes customer feedback into clear, structured tables for business teams.\"),\n","    (\"human\",\n","     f\"{instruction}\\n\"\n","     f\"{context}\\n\"\n","     f\"{input_text}\\n\"\n","     f\"{output_format}\"\n","    ),\n","]\n","\n","# Invoke model\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdJiPsAhm1F7","outputId":"45f5cf46-7a06-46f3-a529-4a9522c0909c","executionInfo":{"status":"ok","timestamp":1762917428840,"user_tz":-420,"elapsed":3073,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Here's a summary of customer opinions for the product development team:\n","\n","| Feature                  | Status (Good/Needs Improvement/Requested) | Notes                                                              |\n","| :----------------------- | :---------------------------------------- | :----------------------------------------------------------------- |\n","| Battery Life             | Good                                      | Lasts up to 3 days, significant improvement over the older version.  |\n","| AMOLED Screen            | Good                                      | Provides vibrant colors and is clearly visible under bright sunlight. |\n","| Bluetooth Connectivity   | Needs Improvement                         | Connections with certain headphones often drop.                    |\n","| Sleep Tracking           | Needs Improvement                         | Not very accurate and sometimes fails to record data.              |\n","| Blood Pressure Monitoring| Requested                                 | Customers would like this function added in the next version.      |\n"]}]},{"cell_type":"markdown","source":["***To summarize, recognizing ICIO when prompting helps ensure the prompt is complete and clear, and that the LLM provides the desired output.***"],"metadata":{"id":"m7g0kOfg4xdy"}},{"cell_type":"markdown","source":["## Combine"],"metadata":{"id":"9hTlvQdLAWUO"}},{"cell_type":"markdown","source":["Note:\n","  - In practice, many modern prompts don't separate system and user instructions. Instead, they combine them into a single, comprehensive prompt.\n","  - This approach is effective because today's large language models are skilled at understanding and following complex, structured instructions.\n","  - You can define the model's persona, give it specific instructions, and provide the necessary data all within one prompt."],"metadata":{"id":"VnE7OTnc_uWc"}},{"cell_type":"code","source":["# Example B: Customer Feedback Summary (Single Prompt)\n","\n","prompt = '''\n","You are a product analyst who summarizes customer feedback into clear, structured tables for business teams.\n","Summarize customer opinions for the product development team to consider improvements in the next version.\n","Customer Opinions:\n","    \"Many customers like the battery lasting up to 3 days, which is much better than the older version. \"\n","    \"The AMOLED screen provides vibrant colors and is clearly visible even under bright sunlight. \"\n","    \"However, some users reported that Bluetooth connections with certain headphones often drop. \"\n","    \"The sleep tracking system is also not very accurate and sometimes fails to record data. \"\n","    \"Additionally, customers would like to see a blood pressure monitoring function added.\"\n","Output: Summarize into a table with 3 columns: \"Feature\", \"Status (Good/Needs Improvement/Requested)\", \"Notes\".\n","'''\n","\n","# Invoke model\n","ai_msg = llm.invoke(prompt)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AkndWCsAOdn","outputId":"0fc904f3-5eef-43dc-d946-8960d356630b","executionInfo":{"status":"ok","timestamp":1762917479891,"user_tz":-420,"elapsed":3678,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Here's a summary of customer opinions for the product development team:\n","\n","| Feature                     | Status (Good/Needs Improvement/Requested) | Notes                                                              |\n","| :-------------------------- | :---------------------------------------- | :----------------------------------------------------------------- |\n","| Battery Life                | Good                                      | Lasts up to 3 days, significant improvement over older version.    |\n","| AMOLED Screen / Display     | Good                                      | Provides vibrant colors and is clearly visible under bright sunlight. |\n","| Bluetooth Connectivity      | Needs Improvement                         | Connections with certain headphones often drop.                    |\n","| Sleep Tracking              | Needs Improvement                         | Not very accurate and sometimes fails to record data.              |\n","| Blood Pressure Monitoring   | Requested                                 | Customers would like to see this function added.                   |\n"]}]},{"cell_type":"markdown","source":["## Structured Input"],"metadata":{"id":"mKdBOwfBnlDX"}},{"cell_type":"markdown","source":["In prompt engineering, **structured input** helps guide the LLM to focus on exactly what we want.  \n","\n","One common technique is using **delimiters** (special symbols or markers) to clearly separate instructions, context, and input data.\n","\n","\n","Why use delimiters?\n","- They **reduce ambiguity** → the model doesn’t “guess” where instructions or content begin/end.  \n","- They **minimize misinterpretation** → the model treats the content inside delimiters as a defined block.  \n","- They are especially useful when prompts are **long, multi-part, or contain different types of information**.\n","---\n","\n","Examples of delimiters\n","\n","You can use different symbols such as:\n","- Triple dashes (---)\n","- Triple hashtags (###)\n","- Triple backticks: \\`\\`\\` ... \\`\\`\\`\n","- Triple quotes: \"\"\" ... \"\"\"\n","- Angle brackets: < ... >\n","- Tags: `<instruction> ... </instruction>`"],"metadata":{"id":"H3oDxvd0p0Hz"}},{"cell_type":"code","source":["# The raw text to be summarized\n","text = \"\"\"\n","In the digital age, online marketing has become the cornerstone of businesses of all sizes, offering a broad reach to consumers at a lower cost than traditional marketing.\n","Popular online marketing tools include SEO (Search Engine Optimization), Social Media Marketing, and high-quality Content Marketing.\n","Leveraging data analytics also helps businesses analyze customer behavior and refine their strategies effectively.\n","\"\"\"\n","\n","# The prompt using delimiters (triple backticks ```)\n","prompt = f\"\"\"You are a helpful assistant.\n","Summarize the text within the triple backticks concisely, in no more than two sentences.\n","\n","```{text}```\n","\"\"\"\n","\n","ai_msg = llm.invoke(prompt)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0We1kF19Tea","outputId":"eb3eca75-38f2-467d-a926-cb04253e530a","executionInfo":{"status":"ok","timestamp":1762917501477,"user_tz":-420,"elapsed":1567,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Online marketing is essential for businesses today, offering broad consumer reach at a lower cost than traditional methods. Key tools include SEO, social media, and content marketing, with data analytics further refining strategies based on customer behavior.\n"]}]},{"cell_type":"code","source":["prompt = f\"\"\"\n","<Instructions>\n","You are a marketing expert. Analyze the article within <Article> and provide recommendations based on the topics outlined in <Response_Format>.\n","</Instructions>\n","\n","<Article>\n","Our company recently launched a new smartwatch, but sales have been disappointing. Most customers say the features aren't unique compared to competitors, and the price is too high for the value they receive.\n","</Article>\n","\n","<Response_Format>\n","### Problem Analysis:\n","- [Summary of main issues]\n","\n","### Strategic Recommendations:\n","- [Suggestion for the product]\n","- [Suggestion for pricing]\n","- [Suggestion for marketing communications]\n","</Response_Format>\n","\"\"\"\n","\n","ai_msg = llm.invoke(prompt)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jlZpQYyQ97Zu","outputId":"f8039404-ff5f-45e1-a834-2318c36616a5","executionInfo":{"status":"ok","timestamp":1762917512448,"user_tz":-420,"elapsed":7375,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["### Problem Analysis:\n","- **Lack of Product Differentiation:** Customers perceive the smartwatch's features as not unique or superior compared to competitors, leading to a commoditized perception.\n","- **Poor Value Perception:** The current price point is deemed too high relative to the value customers believe they receive from the product's features, resulting in low perceived value for money.\n","- **Disappointing Sales:** These core issues have directly translated into poor sales performance for the newly launched smartwatch.\n","\n","### Strategic Recommendations:\n","\n","- **Suggestion for the product:**\n","    *   **Enhance Differentiation:** Conduct a thorough competitive analysis to identify gaps and opportunities. Prioritize developing or highlighting truly unique features, either through software updates (e.g., exclusive health tracking algorithms, unique app integrations, AI capabilities) or by focusing on a specific niche (e.g., extreme sports, senior care, specific professional use).\n","    *   **Re-evaluate Core Value Proposition:** Clearly define what problem the smartwatch solves uniquely or how it significantly improves a user's life compared to alternatives. If no unique features can be added quickly, consider how existing features can be bundled or presented to create a distinct user experience.\n","\n","- **Suggestion for pricing:**\n","    *   **Value-Based Pricing Adjustment:** Re-evaluate the pricing strategy. If the product's features cannot be significantly enhanced in the short term, consider adjusting the price to better align with the current perceived market value. This might involve a price reduction, or introducing a tiered model (e.g., a more basic, lower-priced version alongside a premium one).\n","    *   **Bundle Offerings:** Create compelling bundles that add perceived value without necessarily lowering the base price. This could include premium straps, extended warranty, exclusive app subscriptions, or integration with other company products/services.\n","    *   **Justify Value:** If the current price is strategically important, invest in clearly articulating the *hidden* value or long-term benefits that justify the cost (e.g., superior build quality, data privacy, ecosystem integration, future-proofing).\n","\n","- **Suggestion for marketing communications:**\n","    *   **Shift Focus from Features to Benefits & Solutions:** Instead of listing features, communicate the tangible benefits and solutions the smartwatch provides. For example, instead of \"heart rate monitor,\" say \"gain peace of mind with continuous heart health monitoring.\"\n","    *   **Highlight Unique Selling Proposition (if any):** If any aspect of the product *is* unique (even if subtle, like design, battery life, or specific software integration), make it the cornerstone of all marketing messages. If true uniqueness is absent, focus on a compelling narrative around user experience, reliability, or a specific lifestyle.\n","    *   **Address Value Perception Directly:** Create messaging that directly tackles the \"value for money\" concern. This could involve comparisons (if favorable), testimonials from early adopters who *do* see the value, or demonstrating the long-term savings/benefits that justify the initial investment.\n","    *   **Target Specific Segments:** If the product has niche strengths, refine targeting to reach specific customer segments who would genuinely appreciate and pay for those particular features or benefits, rather than trying to appeal to a broad market.\n"]}]},{"cell_type":"markdown","source":["Explanation:\n","\n","- `<Instructions>`: Sets the model's persona and primary objective.\n","\n","- `<Article>`: Contains the raw data to be analyzed.\n","\n","- `<Response_Format>`: Clearly outlines the desired structure of the output. This forces the model to organize its response systematically and address all specified points.\n","\n"],"metadata":{"id":"BzHT8XuQ-5En"}},{"cell_type":"markdown","source":["## Structured Output"],"metadata":{"id":"1-MIkua_qMkJ"}},{"cell_type":"markdown","source":["`CSV` is best reserved for situations where the data is exclusively flat and **tabular**, like a basic spreadsheet.\n","\n","`JSON` is the clear winner for most tasks today because it can handle **hierarchical and nested data**. This is essential for working with APIs, configurations, and any data that isn't a simple table. It also natively supports data types like integers, strings, and booleans, which simplifies processing."],"metadata":{"id":"HJ40UxIZqQe9"}},{"cell_type":"markdown","source":["### Output : CSV"],"metadata":{"id":"eI45ATexGx3I"}},{"cell_type":"code","source":["# Example: Structured output (CSV)\n","prompt = \"\"\"You are a helpful assistant.\n","**Task:** Convert the following customer list into a CSV string.\n","**Output Format:** The first row should contain the headers \"Name\" and \"City\". The subsequent rows should contain the customer data, with values separated by commas.\n","**Data:**\n","- John Doe from New York\n","- Jane Smith from London\n","- Peter Jones from Tokyo\n","\"\"\"\n","\n","ai_msg_csv = llm.invoke(prompt)\n","print(\"Structured Output:\\n\", ai_msg_csv.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1N_Awr4qPtT","outputId":"7f853f79-2fbd-45c2-f25b-2d3a72a97933","executionInfo":{"status":"ok","timestamp":1762917518123,"user_tz":-420,"elapsed":1915,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Structured Output:\n"," ```csv\n","Name,City\n","John Doe,New York\n","Jane Smith,London\n","Peter Jones,Tokyo\n","```\n"]}]},{"cell_type":"markdown","source":["#### Parsing CSV Output into a DataFrame"],"metadata":{"id":"snb2aS38F04e"}},{"cell_type":"markdown","source":["We used a regex pattern to find the ```csv``` content and convert them into a DataFrame."],"metadata":{"id":"Tpz49DBWF6Up"}},{"cell_type":"code","source":["import re\n","import pandas as pd\n","import io\n","\n","def csv_string_to_df(text: str) -> pd.DataFrame:\n","    \"\"\"\n","    Extracts CSV content from a string and converts it into a pandas DataFrame.\n","\n","    Args:\n","        text (str): The input string containing CSV content enclosed in ```csv...```.\n","\n","    Returns:\n","        pd.DataFrame: A pandas DataFrame containing the extracted data.\n","    \"\"\"\n","    # Use a regex pattern to find the content between the delimiters\n","    match = re.search(r'```csv\\s(.*?)```', text, re.DOTALL)\n","\n","    if match:\n","        # Extract the content from the first capturing group\n","        csv_content = match.group(1).strip()\n","\n","        # Use io.StringIO to treat the string as a file\n","        data = io.StringIO(csv_content)\n","\n","        # Read the \"file\" into a pandas DataFrame\n","        df = pd.read_csv(data)\n","\n","        return df\n","    else:\n","        # Return an empty DataFrame or raise an error if no match is found\n","        print(\"No CSV content found within ```csv...``` delimiters.\")\n","        return pd.DataFrame()"],"metadata":{"id":"9F0mecNaEi3f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["csv_string_to_df(ai_msg_csv.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"rmEcEtk7GE8q","outputId":"5b226f28-32c0-4287-9d8f-4c564cbcf8a8","executionInfo":{"status":"ok","timestamp":1762917523369,"user_tz":-420,"elapsed":14,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          Name      City\n","0     John Doe  New York\n","1   Jane Smith    London\n","2  Peter Jones     Tokyo"],"text/html":["\n","  <div id=\"df-33ae9c17-2933-4613-b16f-af17e08855c5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>City</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>John Doe</td>\n","      <td>New York</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jane Smith</td>\n","      <td>London</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Peter Jones</td>\n","      <td>Tokyo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33ae9c17-2933-4613-b16f-af17e08855c5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-33ae9c17-2933-4613-b16f-af17e08855c5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-33ae9c17-2933-4613-b16f-af17e08855c5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-5ef4b482-dadb-4119-96f3-267c3a5a9800\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ef4b482-dadb-4119-96f3-267c3a5a9800')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-5ef4b482-dadb-4119-96f3-267c3a5a9800 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"csv_string_to_df(ai_msg_csv\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"John Doe\",\n          \"Jane Smith\",\n          \"Peter Jones\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"New York\",\n          \"London\",\n          \"Tokyo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["### Output : JSON"],"metadata":{"id":"qUqbr39-G8kl"}},{"cell_type":"code","source":["# Example: Structured output (JSON)\n","prompt = \"\"\"\n","You are a helpful assistant.\n","For the given student record, return a JSON object with the following fields:\n","- name (string) → student’s full name\n","- age (integer) → student’s age\n","- scores (object) → nested dictionary with subject name as key and integer score as value\n","- extracurricular (array of strings) → list of activities\n","\n","Student Record:\n","Alice, 21 years old. Math = 85, English = 92. She joined Basketball and Drama Club.\n","\n","Answer:\n","\"\"\"\n","\n","ai_msg_json = llm.invoke(prompt)\n","print(\"Structured Output:\\n\", ai_msg_json.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7713636a-07fa-4140-f661-40befe39567f","id":"PkbM0hvuG8kl","executionInfo":{"status":"ok","timestamp":1762917527814,"user_tz":-420,"elapsed":1458,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Structured Output:\n"," ```json\n","{\n","  \"name\": \"Alice\",\n","  \"age\": 21,\n","  \"scores\": {\n","    \"Math\": 85,\n","    \"English\": 92\n","  },\n","  \"extracurricular\": [\n","    \"Basketball\",\n","    \"Drama Club\"\n","  ]\n","}\n","```\n"]}]},{"cell_type":"markdown","source":["#### Parsing JSON Output into Dict"],"metadata":{"id":"e6UZdGS6G8kl"}},{"cell_type":"markdown","source":["We used a regex pattern to find the ```csv``` content and convert them into a DataFrame."],"metadata":{"id":"pbYRVsTRG8kl"}},{"cell_type":"code","source":["import re\n","import json\n","\n","def json_string_to_dict(text: str):\n","    \"\"\"\n","    Extracts JSON content from a string enclosed in ```json...```\n","    and parses it into a Python dict or list.\n","\n","    Args:\n","        text (str): The input string containing JSON content enclosed in ```json...```.\n","\n","    Returns:\n","        dict or list: Parsed JSON object (Python dict or list).\n","    \"\"\"\n","    # Use regex to find JSON block\n","    match = re.search(r'```json\\s(.*?)```', text, re.DOTALL)\n","\n","    if match:\n","        # Extract JSON content\n","        json_content = match.group(1).strip()\n","\n","        try:\n","            return json.loads(json_content)\n","        except json.JSONDecodeError as e:\n","            print(\"Invalid JSON:\", e)\n","            return None\n","    else:\n","        print(\"No JSON content found within ```json...``` delimiters.\")\n","        return None"],"metadata":{"id":"mVl5noz0M8AX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dict_output = json_string_to_dict(ai_msg_json.content)\n","dict_output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUIY-djMM-P_","outputId":"388212eb-fb83-457b-cf7e-86b4f0260994","executionInfo":{"status":"ok","timestamp":1762917535359,"user_tz":-420,"elapsed":18,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'name': 'Alice',\n"," 'age': 21,\n"," 'scores': {'Math': 85, 'English': 92},\n"," 'extracurricular': ['Basketball', 'Drama Club']}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["dict_output['scores']['Math']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KjqbbnvNeE4","outputId":"60d3f4d5-c2a4-41c1-cb9c-146d44b0803e","executionInfo":{"status":"ok","timestamp":1762917536669,"user_tz":-420,"elapsed":16,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["85"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["### Output : Pydantic Schema"],"metadata":{"id":"QR96B7zq0pfm"}},{"cell_type":"markdown","source":["- LangChain supports structured outputs, **allowing us to bind a schema (dict / JSON Schema / Pydantic) to the model**\n","  - and enforce responses to follow the defined structure instead of relying only on prompt wording.\n","- ***However, complex output structures may still fail, so prompting and custom parsing function are still important in some cases.***\n","\n","Read more: [LangChain Docs – Structured Outputs](https://python.langchain.com/docs/concepts/structured_outputs/)\n"],"metadata":{"id":"V9xRrjgy09pD"}},{"cell_type":"code","source":["# pydantic schema\n","\n","# suppose that we want the output something like this :\n","'''{'name': 'Alice',\n"," 'age': 21,\n"," 'scores': {'Math': 85, 'English': 92},\n"," 'extracurricular': ['Basketball', 'Drama Club']}'''\n","\n","# we can defined class (data fields) like this\n","\n","from typing import Dict, List\n","from pydantic import BaseModel, Field\n","\n","class DesiredOutput(BaseModel):\n","    name: str = Field(description=\"Student's first name\")\n","    age: int = Field(description=\"Age in years\")\n","    extracurricular: List[str] = Field(description=\"List of activities/clubs\")\n","\n","    #subject_scores: Dict[str, int] = Field(description=\"Key = subject, Value = scores (as a JSON object)\")\n","\n","    # This line cause an error. / Complex Data Structure (uncomment if you want to test it)"],"metadata":{"id":"DLSKUOVy0uN2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Wrap LLM so it returns a DesiredOutput object directly\n","structured_llm = llm.with_structured_output(DesiredOutput)"],"metadata":{"id":"LNMNByvN27fS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"\"\"\n","You are a helpful assistant.\n","For the given student record, extract informations\n","\n","Student Record:\n","Alice, 21 years old. Math = 85, English = 92. She joined Basketball and Drama Club.\n","\n","Answer:\n","\"\"\"\n","\n","\n","# Generate output\n","results = structured_llm.invoke(prompt)\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJc0JMrS3pld","outputId":"95188535-878c-47b9-b131-ba4d82b8cb08","executionInfo":{"status":"ok","timestamp":1762917547351,"user_tz":-420,"elapsed":1574,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DesiredOutput(name='Alice', age=21, extracurricular=['Basketball', 'Drama Club'])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["results.model_dump_json()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"fqArflod__Q4","outputId":"7a4d5efa-b4fb-4e4a-ded5-fe2810e9c540","executionInfo":{"status":"ok","timestamp":1762917551684,"user_tz":-420,"elapsed":9,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'{\"name\":\"Alice\",\"age\":21,\"extracurricular\":[\"Basketball\",\"Drama Club\"]}'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["## Boundary Condition\n","- **Don't know, don't guess**  \n","  Instruct the model to answer *\"I don’t know\"* if the information is unknown or unverifiable.  \n","  → Helps prevent the model from attempting to answer overly difficult or specific open-ended questions.  \n","  > Note: This depends on the **use case** — but in scenarios where we *don’t want the model to attempt an uncertain answer*, this condition is very useful.\n","\n","- **Output Format Remarking**  \n","  Explicitly remind the model about the required output format.  \n","  → e.g., *\"Don’t give any additional explanation, just output [format] only.\"*"],"metadata":{"id":"3xeHCngFhtAK"}},{"cell_type":"code","source":["# Example 1: Without boundary condition\n","prompt = \"\"\"\n","What are the details of the announcement from the Meteorological Department, Announcement No. 2/2025, regarding ‘Measures to Cope with the Early Arrival of Summer Storms’?\n","\"\"\"\n","\n","ai_msg = llm.invoke(prompt)\n","print(\"Without boundary condition:\\n\", ai_msg.content)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVMrB0dcd1ic","outputId":"dcfdeafb-bb75-4515-fe13-f2130fe8eea9","executionInfo":{"status":"ok","timestamp":1762918085856,"user_tz":-420,"elapsed":15154,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Without boundary condition:\n"," As an AI, I must first clarify that **Announcement No. 2/2025 from the Meteorological Department regarding ‘Measures to Cope with the Early Arrival of Summer Storms’ does not exist yet**, as the current year is 2024. Official announcements are made in real-time based on prevailing weather conditions and forecasts.\n","\n","Therefore, I cannot provide you with actual details of a future announcement.\n","\n","However, I can provide a **hypothetical outline** of what such an announcement *would likely contain*, based on typical meteorological warnings and disaster preparedness measures for early summer storms (which often involve thunderstorms, heavy rain, strong winds, lightning, and potential flash floods).\n","\n","---\n","\n","**Hypothetical Outline of Meteorological Department Announcement No. 2/2025**\n","\n","**Subject:** Measures to Cope with the Early Arrival of Summer Storms\n","\n","**Issuing Authority:** Meteorological Department [Country Name/Region]\n","\n","**Announcement No.:** 2/2025\n","\n","**Date:** [e.g., Early March 2025]\n","\n","**Key Points/Summary:**\n","The Meteorological Department advises the public to prepare for the early onset of summer storms, characterized by intense thunderstorms, heavy rainfall, strong gusty winds, frequent lightning, and potential for hail and flash floods. This early arrival is attributed to [brief explanation, e.g., unusual atmospheric pressure systems, early warming trends]. All residents, particularly those in low-lying areas or near waterways, are urged to take precautionary measures immediately.\n","\n","**Detailed Measures and Recommendations:**\n","\n","1.  **Current Weather Situation & Forecast:**\n","    *   **Early Onset:** Confirmation of summer storm conditions arriving earlier than the typical season.\n","    *   **Affected Areas:** Specific regions, provinces, or districts expected to be most impacted.\n","    *   **Expected Conditions:** Detailed forecast including:\n","        *   Intensity and duration of rainfall (e.g., \"heavy to very heavy rainfall\").\n","        *   Wind speeds (e.g., \"strong winds with gusts up to X km/h\").\n","        *   Risk of lightning, hail, and flash floods.\n","        *   Potential for landslides in hilly areas.\n","    *   **Duration:** Indication of how long these conditions are expected to persist (e.g., \"over the next 3-5 days\").\n","\n","2.  **Recommendations for the General Public:**\n","    *   **Stay Informed:** Continuously monitor official weather updates from the Meteorological Department via radio, TV, official websites, and social media.\n","    *   **Secure Property:**\n","        *   Tie down or move loose objects outdoors (e.g., garden furniture, advertising boards, roofing materials) that could be blown away by strong winds.\n","        *   Ensure drainage systems around homes are clear to prevent localized flooding.\n","    *   **Emergency Preparedness:**\n","        *   Prepare an emergency kit including water, non-perishable food, first-aid supplies, flashlights, extra batteries, and essential medications.\n","        *   Charge mobile phones and power banks.\n","    *   **Safety During Storms:**\n","        *   **Seek Shelter:** Stay indoors in a sturdy building. Avoid temporary structures or under large trees.\n","        *   **Lightning Safety:** Unplug electrical appliances. Avoid using landline phones. Stay away from windows and metal objects.\n","        *   **Driving:** Avoid unnecessary travel. If driving, be extremely cautious, reduce speed, and be aware of slippery roads, reduced visibility, and potential debris. Do not drive through flooded areas.\n","        *   **Flooding:** If in a flood-prone area, be prepared to evacuate to higher ground if advised by authorities. Do not walk or drive through floodwaters.\n","    *   **Power Outages:** Be prepared for potential power disruptions.\n","    *   **Children and Elderly:** Ensure vulnerable family members are safe and aware of precautions.\n","\n","3.  **Recommendations for Local Authorities and Emergency Services:**\n","    *   **Activate Emergency Plans:** Local disaster management committees should activate their emergency response plans.\n","    *   **Monitor High-Risk Areas:** Closely monitor low-lying areas, riverbanks, and landslide-prone zones.\n","    *   **Public Awareness:** Disseminate warnings and safety information widely through local channels.\n","    *   **Resource Mobilization:** Prepare emergency shelters, rescue teams, and necessary equipment (e.g., boats, sandbags).\n","    *   **Infrastructure Checks:** Inspect and secure critical infrastructure, including power lines, communication networks, and transportation routes.\n","    *   **Coordination:** Maintain close coordination with other relevant agencies (e.g., police, fire department, health services).\n","\n","4.  **Specific Sector Advisories:**\n","    *   **Agriculture:** Farmers should take measures to protect crops and livestock from heavy rain and strong winds.\n","    *   **Fisheries/Maritime:** Small vessels and fishing boats are advised to remain in port or exercise extreme caution due to rough seas and strong winds.\n","    *   **Construction:** Construction sites should secure equipment and materials to prevent accidents.\n","\n","**Further Information & Emergency Contacts:**\n","*   For the latest updates, visit [Meteorological Department Website] or call [Hotline Number].\n","*   In case of emergencies, contact [Emergency Services Number, e.g., 911/112].\n","\n","**Conclusion:**\n","The Meteorological Department urges all citizens to remain vigilant, take these precautionary measures seriously, and cooperate with local authorities to ensure safety and minimize potential damage from the early summer storms.\n","\n","---\n","\n","This hypothetical outline covers the essential elements typically found in such official weather warnings, focusing on informing the public, advising on safety measures, and coordinating emergency responses.\n"]}]},{"cell_type":"markdown","source":["**Key Takeaways**:\n","- Without boundary conditions, an LLM will still attempt to generate an answer — sometimes hallucinating content, and other times making an estimated guess while recognizing its own uncertainty.\n","- If you want to avoid such cases, define clear boundary conditions that tell the LLM to respond with `“I don’t know”` or another `concise fallback` instead of producing uncertain or fabricated answers.\n","- This keeps your system consistent and predictable."],"metadata":{"id":"culOGTStHBct"}},{"cell_type":"code","source":["# Example 2: With boundary condition\n","prompt = \"\"\"\n","What are the details of the announcement from the Meteorological Department, Announcement No. 2/2025, regarding ‘Measures to Cope with the Early Arrival of Summer Storms’?\n","\n","If the answer is not known or cannot be verified, just reply: `I don’t know`.\n","\"\"\"\n","\n","ai_msg = llm.invoke(prompt)\n","print(\"With boundary condition:\\n\", ai_msg.content)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zFYUTpPeyR4v","outputId":"1519cca0-65ed-4ca6-8f74-40d94848c9ef","executionInfo":{"status":"ok","timestamp":1762918129542,"user_tz":-420,"elapsed":2045,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["With boundary condition:\n"," I don’t know.\n"]}]},{"cell_type":"markdown","source":["## Prompt Template\n","\n","Prompt templates offer several benefits:\n","\n","- **Consistency**: Ensure a consistent structure for your prompts across multiple interactions\n","- **Efficiency**: Easily swap out variable content without rewriting the entire prompt\n","- **Testability**: Quickly test different inputs and edge cases by changing only the variable portion\n","- **Scalability***: Simplify prompt management as your application grows in complexity\n","- **Version control**: Easily track changes to your prompt structure over time by keeping tabs only on the core part of your prompt, separate from dynamic inputs"],"metadata":{"id":"UyIZT0fiz-x9"}},{"cell_type":"markdown","source":["### Example: Prompt Template in a Loop (Task: Sentiment Analysis)\n","\n","Example Task: **Sentiment Analysis**\n","\n","We used a prompt template with the approach **“run in a loop + change only variables”**.  \n","This demonstrates how prompt templates cover several benefits at once:\n","\n","- **Consistency**: Every iteration uses the same prompt structure.  \n","- **Efficiency**: Only the variable `{text}` changes in each loop.  \n","- **Testability**: Multiple inputs can be tested quickly by swapping variable values.  \n","- **Scalability**: The same template can be applied to a larger dataset without modification.  \n","- **Version Control**: Easily track prompt versions against results.\n","\n","\n"],"metadata":{"id":"3R-tfOsrRG7A"}},{"cell_type":"code","source":["!wget https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt"],"metadata":{"id":"4ryOL6guq0C-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"08e9c499-64b2-49dd-f1c9-587a564e314f","executionInfo":{"status":"ok","timestamp":1762917601929,"user_tz":-420,"elapsed":905,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-11-12 03:20:07--  https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt\n","Resolving github.com (github.com)... 20.27.177.113\n","Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt [following]\n","--2025-11-12 03:20:07--  https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 122071 (119K) [text/plain]\n","Saving to: ‘dev.txt’\n","\n","dev.txt             100%[===================>] 119.21K  --.-KB/s    in 0.06s   \n","\n","2025-11-12 03:20:08 (2.11 MB/s) - ‘dev.txt’ saved [122071/122071]\n","\n"]}]},{"cell_type":"code","source":["def read_xy_data(filename: str) -> tuple[list[str], list[int]]:\n","    x_data = []\n","    y_data = []\n","    with open(filename, 'r') as f:\n","        for line in f:\n","            label, text = line.strip().split(' ||| ')\n","            x_data.append(text)\n","            y_data.append(int(label))\n","    return x_data, y_data"],"metadata":{"id":"fXa_FpBL6zt2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_test, y_test = read_xy_data('dev.txt')\n","x_test, y_test = x_test[:10], y_test[:10] # small size for quick testing"],"metadata":{"id":"IbNrlgaWRVz_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For sentiment analysis, we will be using the following prompt:\n","\n","```\n","Analyse the sentiment of the following text: ```text```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","```\n","LLMs nowaday usually have chain-of-thought baked in so they usually will output their reasoning before answering.\n","\n","- It is important to tell the model not to output their explanation by including `**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","`\n","- Otherwise, it will not be easy to programmatically use the outputs.\n","Alternatively, you can use structured outputs `(see table of contents -> Structured Output)` for ease of parsing."],"metadata":{"id":"6EU6prW_oeTF"}},{"cell_type":"code","source":["prompt_template = \"\"\"\n","Analyse the sentiment of the following text: ```{x_input}```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\"\"\""],"metadata":{"id":"y3wwc3vJiiJO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm.notebook import tqdm"],"metadata":{"id":"Py85PRxuXwjN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output = []\n","for sent in tqdm(x_test):\n","   try:\n","      prompt_filled = prompt_template.format(x_input=sent)\n","      print('prompt:', prompt_filled) # debugging\n","      output_res = llm.invoke(prompt_filled).content.strip()\n","      print('response:', output_res) # debugging\n","      print('--'*20)\n","      output.append(int(output_res))\n","   except:\n","      output.append(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e85183467d2b428fa787422d65410ebf","11b527e0250749b0bcdb0b00d9b8efa0","94e0e8191ea44af5b84d309b3cee9b80","f5cc9dfc46f248b082dc6784bd8ee47e","64f721c6438647008ad61a13c46306b0","e14386b9c01642ac840e938d18d74cb3","38288475755d444b9f59e43fdf15694d","29737e3418824aed9eb519735367d965","e5ba80bf20fe4deca5245a732b0e1406","7c8c84bfa9034f30b3afd1e56eeb2386","40fcc477884245628dfc8a0a6fb0e720"]},"id":"QFFPVtwT9rjZ","outputId":"bdd56d94-ca0a-440b-869d-4b001334201d","executionInfo":{"status":"ok","timestamp":1762917635264,"user_tz":-420,"elapsed":21314,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e85183467d2b428fa787422d65410ebf"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["prompt: \n","Analyse the sentiment of the following text: ```It 's a lovely film with lovely performances by Buy and Accorsi .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```No one goes unindicted here , which is probably for the best .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```And if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```A warm , funny , engaging film .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Uses sharp humor and insight into human nature to examine class conflict , adolescent yearning , the roots of friendship and sexual identity .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Half Submarine flick , Half Ghost Story , All in one criminally neglected film```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Entertains by providing good , lively company .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Dazzles with its fully-written characters , its determined stylishness -LRB- which always relates to characters and story -RRB- and Johnny Dankworth 's best soundtrack in years .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Visually imaginative , thematically instructive and thoroughly delightful , it takes us on a roller-coaster ride from innocence to experience without even a hint of that typical kiddie-flick sentimentality .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Nothing 's at stake , just a twisty double-cross you can smell a mile away -- still , the derivative Nine Queens is lots of fun .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test, output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dp7ZS8hKVRb8","outputId":"cbfaf20e-642f-4a88-9ff4-1f51f800d7d5","executionInfo":{"status":"ok","timestamp":1762917636626,"user_tz":-420,"elapsed":949,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["## Additional: Temperature Setting"],"metadata":{"id":"_AryYrz0F-Pr"}},{"cell_type":"markdown","source":["Settings to keep in mind\n","\n","- Temperature is an important parameter to consider.\n","  - Keep it low if you are looking for exact or deterministic answers.\n","  - Keep it high if you are looking for more diverse or creative responses.\n","\n","> In all the previous examples, we only set up the LLM once, and the parameter was fixed as Temperature = 0\n","\n","This means every example so far was generated with a deterministic setting (no randomness)."],"metadata":{"id":"oNWq0plMFcEV"}},{"cell_type":"markdown","source":["Temperature Range for Gemini-2.5-flash : 0-2 (default 1)\n","\n",">Ref: https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash"],"metadata":{"id":"mJA6w0hAdyxg"}},{"cell_type":"code","source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm_low_temp = ChatGoogleGenerativeAI(\n","    model=\"gemini-2.5-flash\",\n","    temperature=0,\n","    max_tokens=None,\n","    timeout=None,\n","    max_retries=2,\n","    # other params...\n",")"],"metadata":{"id":"1LscvX8fjVzY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm_high_temp = ChatGoogleGenerativeAI(\n","    model=\"gemini-2.5-flash\",\n","    temperature=2,\n","    max_tokens=None,\n","    timeout=None,\n","    max_retries=2,\n","    # other params...\n",")"],"metadata":{"id":"gx4NPLujeWZN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# llm_low_temp\n","prompt = \"Write one slogan for a mobile banking application. Just only answer the slogan without additional suggestions\"\n","for rnd in range(3):\n","  try:\n","    output_res = llm_low_temp.invoke(prompt).content.strip()\n","    print(f\"Round {rnd+1} | response:\", output_res)\n","  except Exception as e:\n","    print(f\"Round {rnd+1} | Error:\", e)\n","\n","  print(\"--\"*30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kbra6aNZgtM3","outputId":"6cbab12d-63d3-4b43-a77b-5c7cd13b6b23","executionInfo":{"status":"ok","timestamp":1762917777550,"user_tz":-420,"elapsed":14454,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Round 1 | response: Your bank, always in reach.\n","------------------------------------------------------------\n","Round 2 | response: Your bank, always in reach.\n","------------------------------------------------------------\n","Round 3 | response: Your bank, always with you.\n","------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["# llm_high_temp\n","prompt = \"Write one slogan for a mobile banking application. Just only answer the slogan without additional suggestions\"\n","for rnd in range(3):\n","  try:\n","    output_res = llm_high_temp.invoke(prompt).content.strip()\n","    print(f\"Round {rnd+1} | response:\", output_res)\n","  except Exception as e:\n","    print(f\"Round {rnd+1} | Error:\", e)\n","\n","  print(\"--\"*30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dAlpPN-nhd4w","outputId":"7725dece-0e55-46c8-8662-3b24a8544d80","executionInfo":{"status":"ok","timestamp":1762917800434,"user_tz":-420,"elapsed":13686,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Round 1 | response: Your Money, On Your Terms.\n","------------------------------------------------------------\n","Round 2 | response: Banking at Your Fingertips.\n","------------------------------------------------------------\n","Round 3 | response: Your bank, at your fingertips.\n","------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["Summary\n","\n","- Low temp → Reliable, consistent outputs. Useful for classification, extraction, or when you want reproducibility.\n","- High temp → Diverse, creative slogans. Useful for brainstorming, ideation, or when multiple fresh options are desired."],"metadata":{"id":"jp0VKZZVhzsD"}}]}
||||||| empty tree
=======
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1QiG4zWZdW2uli2gP3kefLb-J6AKcGduq","timestamp":1762917830714},{"file_id":"1QxDB72JWQWjrFlUKwfx_i-f84wGmS87T","timestamp":1762916838842},{"file_id":"https://github.com/pvateekul/2190513_DS-ICE_2025s1/blob/main/code/Week12_GenerativeAI/7_2_LLM_Prompt_Engineering_Basic_LangChain.ipynb","timestamp":1762916612684}],"toc_visible":true,"collapsed_sections":["26-zG4kznPuU"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a586e130729a4594a36a5c910cd19f28":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7dce6349ce28416a9cc4b32f5593a3f2","IPY_MODEL_75e1164c2e204b2da07ed040c5d507f5","IPY_MODEL_2574f0eccc4b424288b4ba2a79575c6c"],"layout":"IPY_MODEL_91a4d91f0b604ac4b76697cd09240a62"}},"7dce6349ce28416a9cc4b32f5593a3f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a36a2b9b7a441419806e1fb865c1c04","placeholder":"​","style":"IPY_MODEL_4d841c3f700241328a251ff20db6fa6f","value":"100%"}},"75e1164c2e204b2da07ed040c5d507f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0248a72dbcd64bb4990acc232d6c56a9","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f292ca2b0e22459186fe6ca4393ba01c","value":10}},"2574f0eccc4b424288b4ba2a79575c6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a6a90d8d9f44733a88d194ddeb48923","placeholder":"​","style":"IPY_MODEL_7514e797200442f2b47542b6a0d42ca2","value":" 10/10 [00:21&lt;00:00,  2.19s/it]"}},"91a4d91f0b604ac4b76697cd09240a62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a36a2b9b7a441419806e1fb865c1c04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d841c3f700241328a251ff20db6fa6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0248a72dbcd64bb4990acc232d6c56a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f292ca2b0e22459186fe6ca4393ba01c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a6a90d8d9f44733a88d194ddeb48923":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7514e797200442f2b47542b6a0d42ca2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["Due to the current situation (`Updated 09/02/2026`),\n","\n","- Google Gemini has reduced the rate limits for several models, such as `gemini-2.5-flash` and `gemini-3-flash` (text models used in Colab notebooks), to a **limit of 20 Requests Per Day (RPD)**.\n","\n","- To continue using these models seamlessly with sufficient rate limits, it is necessary to upgrade to the **pay-as-you-go tier** (link a Billing Account).\n","  - 👉 You can learn how to do this here: [https://ai.google.dev/gemini-api/docs/billing](https://ai.google.dev/gemini-api/docs/billing)\n","\n","- Alternatively, you can follow the Groq API approach described below.\n"],"metadata":{"id":"6bLkLM6QcD8m"}},{"cell_type":"markdown","source":["# Overall of this notebook"],"metadata":{"id":"VXSQW2RpFSYe"}},{"cell_type":"markdown","source":["Most of concepts and codes are adapted from\n","- https://github.com/dair-ai/Prompt-Engineering-Guide\n","- https://ai.google.dev/gemini-api/docs/prompting-strategies\n","- https://myframework.net/icio-ai-prompt-framework/"],"metadata":{"id":"uwrZRFXNFj74"}},{"cell_type":"markdown","source":["# Setting environments and model setup"],"metadata":{"id":"tXNDggfzh28Q"}},{"cell_type":"markdown","source":["## Approach 1: Gemini"],"metadata":{"id":"gac5oO3pj2Mj"}},{"cell_type":"code","source":["# %%capture\n","# !pip install -qU langchain-google-genai"],"metadata":{"id":"ZRhhli6S3UkP","executionInfo":{"status":"ok","timestamp":1770648011525,"user_tz":-420,"elapsed":58,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Request for Google API KEY here : https://aistudio.google.com/app/apikey"],"metadata":{"id":"3sT4diEh3gUJ"}},{"cell_type":"code","source":["# from getpass import getpass\n","# import os\n","\n","# if \"GOOGLE_API_KEY\" not in os.environ:\n","#     os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google AI API key: \")"],"metadata":{"id":"wPsljCqyNPnt","executionInfo":{"status":"ok","timestamp":1770648011528,"user_tz":-420,"elapsed":38,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","# llm = ChatGoogleGenerativeAI(\n","#     model=\"gemini-2.5-flash\",\n","#     temperature=0,\n","#     max_tokens=None,\n","#     timeout=None,\n","#     max_retries=2,\n","#     # other params...\n","# )"],"metadata":{"id":"sbi2CAPqOHef","executionInfo":{"status":"ok","timestamp":1770648011544,"user_tz":-420,"elapsed":21,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Approach 2: Groq API"],"metadata":{"id":"t34XEcouj72D"}},{"cell_type":"markdown","source":["\n","However, we still have an **alternative** that can be used via a free-tier API: **Groq API** (compatible with LangChain). This does not require linking a credit card and offers several models, such as:\n","\n","- `llama-3.1-8b-instant` (Rate limit: 30 RPM, 14.4K RPD) *RPM = Requests Per Minute, RPD = Requests Per Day\n","- `llama-3.3-70b-versatile` (Rate limit: 30 RPM, 1K RPD)\n","- Other available models: https://console.groq.com/settings/limits\n","\n","*(RPM = Requests Per Minute, TPM = Tokens Per Minute)*\n","\n","👉 You can sign up and get your API Key here: [https://console.groq.com/keys](https://console.groq.com/keys)\n"],"metadata":{"id":"mPDA4a1xgsHH"}},{"cell_type":"code","source":["!pip install -qU langchain-groq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4GfwFsZhUBA","executionInfo":{"status":"ok","timestamp":1770648016444,"user_tz":-420,"elapsed":4920,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}},"outputId":"ee43f71d-4821-4372-ee17-dd7b6e93a67b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import getpass\n","import os\n","\n","os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API key: \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J_VGYtIuiANL","executionInfo":{"status":"ok","timestamp":1770648025094,"user_tz":-420,"elapsed":8648,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}},"outputId":"79819b4e-e7ad-4d40-d319-6732c45a42fd"},"execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Groq API key: ··········\n"]}]},{"cell_type":"code","source":["from langchain_groq import ChatGroq\n","\n","llm = ChatGroq(\n","    model=\"llama-3.1-8b-instant\", # can change\n","    temperature=0,\n","    max_tokens=None,\n","    timeout=None,\n","    max_retries=2,\n",")"],"metadata":{"id":"yucHEIvuhmYo","executionInfo":{"status":"ok","timestamp":1770648042439,"user_tz":-420,"elapsed":17346,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Basic"],"metadata":{"id":"enmt8H4Shngs"}},{"cell_type":"markdown","source":["## System Prompt / User Prompt"],"metadata":{"id":"rF6TFz-mFEK-"}},{"cell_type":"markdown","source":["`System Prompt`:\n","\n","The system prompt establishes the overall context, persona, and behavioral guidelines for the LLM. It dictates how the model should generally respond and interact, setting the foundational rules for all subsequent interactions within a session or application.\n","\n","`User Prompt (Human)`:\n","\n","  The user prompt is the specific query or instruction provided by the user to the LLM. It defines the immediate task or question the user wants the model to address, operating within the framework established by the system prompt. example\n"],"metadata":{"id":"6Xuv336sgo_2"}},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYdX-hTxE_vg","outputId":"10ab4b42-6d56-47f6-9439-5fdd365d0529","executionInfo":{"status":"ok","timestamp":1770648043028,"user_tz":-420,"elapsed":579,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Regular exercise is crucial for maintaining physical and mental health, as it reduces the risk of chronic diseases, improves cardiovascular function, enhances cognitive function, and promotes overall well-being.\n"]}],"source":["# Demo 1: System - Health Scientist / User - Explain the importance of exercise\n","messages = [\n","    (\"system\", \"You are a health scientist who always provides factual and evidence-based answers.\"),\n","    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n","]\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"]},{"cell_type":"code","source":["# Demo 2: Syetem - Elderly Person Complaining / User - Explain the importance of exercise\n","messages = [\n","    (\"system\", \"You are an elderly person who often complains.\"),\n","    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n","]\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_y6fndhCsxL9","outputId":"b6d8ba09-2f6b-4fa5-ca01-89734751cb62","executionInfo":{"status":"ok","timestamp":1770648043160,"user_tz":-420,"elapsed":131,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["*sigh* Fine, exercise is supposed to be good for you, keeps the old bones from creaking too much and the heart from giving out, but I swear, it's a chore.\n"]}]},{"cell_type":"code","source":["# Demo 3: System - Mother Explaining to a 5-year-old / User - Explain the importance of exercise\n","messages = [\n","    (\"system\", \"You are a mother who needs to answer questions from a 5-year-old child, always explaining complex topics in the simplest way possible.\"),\n","    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n","]\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2epKy8w5sync","outputId":"676f7f0f-6560-4333-f3fe-1ccee8dbb954","executionInfo":{"status":"ok","timestamp":1770648043418,"user_tz":-420,"elapsed":246,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Exercise is like giving our bodies a big hug from the inside out, making us strong and healthy so we can run, play, and have lots of fun!\n"]}]},{"cell_type":"code","source":["# Demo 4: Professional Assistant (Python factorial)\n","messages = [\n","    (\"system\", \"You are a helpful and informative assistant. Your responses should be clear, concise, and professional. Avoid making assumptions and always ask for clarification if a user's request is ambiguous.\"),\n","    (\"human\", \"Write a Python function that calculates the factorial of a given number.\"),\n","]\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lblLbxY2s2An","outputId":"14160f04-bc3f-439b-9d44-746d7aefff4b","executionInfo":{"status":"ok","timestamp":1770648043990,"user_tz":-420,"elapsed":554,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["**Calculating the Factorial of a Number in Python**\n","=====================================================\n","\n","Here's a simple Python function that calculates the factorial of a given number using recursion and iteration:\n","\n","### Recursive Implementation\n","\n","```python\n","def factorial_recursive(n):\n","    \"\"\"\n","    Calculate the factorial of a number using recursion.\n","\n","    Args:\n","        n (int): The number to calculate the factorial for.\n","\n","    Returns:\n","        int: The factorial of the given number.\n","\n","    Raises:\n","        ValueError: If n is a negative integer.\n","    \"\"\"\n","    if not isinstance(n, int):\n","        raise TypeError(\"Input must be an integer.\")\n","    if n < 0:\n","        raise ValueError(\"Input must be a non-negative integer.\")\n","    elif n == 0 or n == 1:\n","        return 1\n","    else:\n","        return n * factorial_recursive(n - 1)\n","```\n","\n","### Iterative Implementation\n","\n","```python\n","def factorial_iterative(n):\n","    \"\"\"\n","    Calculate the factorial of a number using iteration.\n","\n","    Args:\n","        n (int): The number to calculate the factorial for.\n","\n","    Returns:\n","        int: The factorial of the given number.\n","\n","    Raises:\n","        ValueError: If n is a negative integer.\n","    \"\"\"\n","    if not isinstance(n, int):\n","        raise TypeError(\"Input must be an integer.\")\n","    if n < 0:\n","        raise ValueError(\"Input must be a non-negative integer.\")\n","    result = 1\n","    for i in range(1, n + 1):\n","        result *= i\n","    return result\n","```\n","\n","### Example Usage\n","\n","```python\n","print(factorial_recursive(5))  # Output: 120\n","print(factorial_iterative(5))  # Output: 120\n","```\n","\n","Both functions take an integer `n` as input and return the factorial of `n`. The recursive implementation uses a recursive function call to calculate the factorial, while the iterative implementation uses a loop to achieve the same result. The functions also include input validation to ensure that the input is a non-negative integer.\n"]}]},{"cell_type":"markdown","source":["## User Prompt Framework - ICIO"],"metadata":{"id":"8PNPxY_VFH5C"}},{"cell_type":"markdown","source":["The ICIO framework is a simple and practical method that **helps you structure your prompts** step by step.\n","- `Instruction (I)` --> What do you want the AI to do?\n","\n","  - The instruction should be specific and direct. A clear task helps the AI give you the right kind of output.\n","- `Context (C)` --> Give background information. Why are you doing this task? What’s the situation?\n","\n","  - Context helps the AI better understand your purpose and tone.\n","  - ***Optional, but nice to have.***\n","\n","- `Input (I)` --> What exact text or data should the AI process?\n","  - Provide the content the AI needs to work with.\n","  - Without input data, the AI may guess or go off track. Be clear and complete.\n","\n","- `Output (O)` --> Set the style or format of the output. What should the response look like? What tone or structure do you expect?\n","  - This helps guide the AI to produce the kind of result you want."],"metadata":{"id":"fMZNMsDQFL2a"}},{"cell_type":"code","source":["# Example A: Customer Feedback Summary\n","\n","# ICIO fields\n","instruction = \"Summarize customer opinions.\"\n","context = \"For the product development team to consider improvements in the next version.\"\n","input_text = (\n","    \"Many customers like the battery lasting up to 3 days, which is much better than the older version. \"\n","    \"The AMOLED screen provides vibrant colors and is clearly visible even under bright sunlight. \"\n","    \"However, some users reported that Bluetooth connections with certain headphones often drop. \"\n","    \"The sleep tracking system is also not very accurate and sometimes fails to record data. \"\n","    \"Additionally, customers would like to see a blood pressure monitoring function added.\"\n",")\n","output_format = 'Summarize into a table with 3 columns: \"Feature\", \"Status (Good/Needs Improvement/Requested)\", \"Notes\".'\n","\n","# Create messages\n","messages = [\n","    (\"system\", \"You are a product analyst who summarizes customer feedback into clear, structured tables for business teams.\"),\n","    (\"human\",\n","     f\"{instruction}\\n\"\n","     f\"{context}\\n\"\n","     f\"{input_text}\\n\"\n","     f\"{output_format}\"\n","    ),\n","]\n","\n","# Invoke model\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdJiPsAhm1F7","outputId":"7f13fc65-855a-4df0-e71b-5c0cdb8f2480","executionInfo":{"status":"ok","timestamp":1770648044339,"user_tz":-420,"elapsed":347,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Here's a summary of customer opinions in a table format:\n","\n","| Feature | Status | Notes |\n","| --- | --- | --- |\n","| Battery Life | Good | Lasts up to 3 days, an improvement from the older version |\n","| AMOLED Screen | Good | Provides vibrant colors and is visible under bright sunlight |\n","| Bluetooth Connectivity | Needs Improvement | Often drops connection with certain headphones |\n","| Sleep Tracking System | Needs Improvement | Not very accurate and sometimes fails to record data |\n","| Blood Pressure Monitoring | Requested | Customers would like to see this feature added |\n"]}]},{"cell_type":"markdown","source":["***To summarize, recognizing ICIO when prompting helps ensure the prompt is complete and clear, and that the LLM provides the desired output.***"],"metadata":{"id":"m7g0kOfg4xdy"}},{"cell_type":"markdown","source":["## Combine"],"metadata":{"id":"9hTlvQdLAWUO"}},{"cell_type":"markdown","source":["Note:\n","  - In practice, many modern prompts don't separate system and user instructions. Instead, they combine them into a single, comprehensive prompt.\n","  - This approach is effective because today's large language models are skilled at understanding and following complex, structured instructions.\n","  - You can define the model's persona, give it specific instructions, and provide the necessary data all within one prompt."],"metadata":{"id":"VnE7OTnc_uWc"}},{"cell_type":"code","source":["# Example B: Customer Feedback Summary (Single Prompt)\n","\n","prompt = '''\n","You are a product analyst who summarizes customer feedback into clear, structured tables for business teams.\n","Summarize customer opinions for the product development team to consider improvements in the next version.\n","Customer Opinions:\n","    \"Many customers like the battery lasting up to 3 days, which is much better than the older version. \"\n","    \"The AMOLED screen provides vibrant colors and is clearly visible even under bright sunlight. \"\n","    \"However, some users reported that Bluetooth connections with certain headphones often drop. \"\n","    \"The sleep tracking system is also not very accurate and sometimes fails to record data. \"\n","    \"Additionally, customers would like to see a blood pressure monitoring function added.\"\n","Output: Summarize into a table with 3 columns: \"Feature\", \"Status (Good/Needs Improvement/Requested)\", \"Notes\".\n","'''\n","\n","# Invoke model\n","ai_msg = llm.invoke(prompt)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AkndWCsAOdn","outputId":"8379bca0-78d0-4fbd-8e14-5053029465b8","executionInfo":{"status":"ok","timestamp":1770648044622,"user_tz":-420,"elapsed":282,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["**Customer Feedback Summary Table**\n","\n","| Feature | Status | Notes |\n","| --- | --- | --- |\n","| Battery Life | Good | Lasts up to 3 days, an improvement from the older version |\n","| AMOLED Screen | Good | Provides vibrant colors and is visible under bright sunlight |\n","| Bluetooth Connectivity | Needs Improvement | Drops connection with certain headphones |\n","| Sleep Tracking System | Needs Improvement | Not very accurate and sometimes fails to record data |\n","| Blood Pressure Monitoring | Requested | Customers would like to see this feature added |\n"]}]},{"cell_type":"markdown","source":["## Structured Input"],"metadata":{"id":"mKdBOwfBnlDX"}},{"cell_type":"markdown","source":["In prompt engineering, **structured input** helps guide the LLM to focus on exactly what we want.  \n","\n","One common technique is using **delimiters** (special symbols or markers) to clearly separate instructions, context, and input data.\n","\n","\n","Why use delimiters?\n","- They **reduce ambiguity** → the model doesn’t “guess” where instructions or content begin/end.  \n","- They **minimize misinterpretation** → the model treats the content inside delimiters as a defined block.  \n","- They are especially useful when prompts are **long, multi-part, or contain different types of information**.\n","---\n","\n","Examples of delimiters\n","\n","You can use different symbols such as:\n","- Triple dashes (---)\n","- Triple hashtags (###)\n","- Triple backticks: \\`\\`\\` ... \\`\\`\\`\n","- Triple quotes: \"\"\" ... \"\"\"\n","- Angle brackets: < ... >\n","- Tags: `<instruction> ... </instruction>`"],"metadata":{"id":"H3oDxvd0p0Hz"}},{"cell_type":"code","source":["# The raw text to be summarized\n","text = \"\"\"\n","In the digital age, online marketing has become the cornerstone of businesses of all sizes, offering a broad reach to consumers at a lower cost than traditional marketing.\n","Popular online marketing tools include SEO (Search Engine Optimization), Social Media Marketing, and high-quality Content Marketing.\n","Leveraging data analytics also helps businesses analyze customer behavior and refine their strategies effectively.\n","\"\"\"\n","\n","# The prompt using delimiters (triple backticks ```)\n","prompt = f\"\"\"You are a helpful assistant.\n","Summarize the text within the triple backticks concisely, in no more than two sentences.\n","\n","```{text}```\n","\"\"\"\n","\n","ai_msg = llm.invoke(prompt)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0We1kF19Tea","outputId":"c2fc1f73-5f00-4acc-b7d1-b0eb2efe3841","executionInfo":{"status":"ok","timestamp":1770648044864,"user_tz":-420,"elapsed":241,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Online marketing has become a cornerstone for businesses, offering a broad reach at a lower cost than traditional marketing. Key tools include SEO, social media marketing, content marketing, and data analytics to refine strategies.\n"]}]},{"cell_type":"code","source":["prompt = f\"\"\"\n","<Instructions>\n","You are a marketing expert. Analyze the article within <Article> and provide recommendations based on the topics outlined in <Response_Format>.\n","</Instructions>\n","\n","<Article>\n","Our company recently launched a new smartwatch, but sales have been disappointing. Most customers say the features aren't unique compared to competitors, and the price is too high for the value they receive.\n","</Article>\n","\n","<Response_Format>\n","### Problem Analysis:\n","- [Summary of main issues]\n","\n","### Strategic Recommendations:\n","- [Suggestion for the product]\n","- [Suggestion for pricing]\n","- [Suggestion for marketing communications]\n","</Response_Format>\n","\"\"\"\n","\n","ai_msg = llm.invoke(prompt)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jlZpQYyQ97Zu","outputId":"a693390b-bdcd-4b7d-9037-c64a47edfb5c","executionInfo":{"status":"ok","timestamp":1770648045658,"user_tz":-420,"elapsed":795,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["### Problem Analysis:\n","The main issues with the new smartwatch are:\n","\n","- Lack of unique features compared to competitors, making it difficult to differentiate the product in the market.\n","- High price point that does not provide sufficient value to customers, leading to disappointing sales.\n","\n","### Strategic Recommendations:\n","\n","#### Suggestion for the product:\n","To address the issue of lacking unique features, we recommend the following:\n","\n","- Conduct market research to identify emerging trends and technologies in the smartwatch industry.\n","- Develop a minimum viable product (MVP) that incorporates a unique feature or functionality that sets the smartwatch apart from competitors.\n","- Consider partnering with a popular fitness or wellness brand to integrate their technology into the smartwatch, making it more appealing to customers.\n","- Offer customization options, such as interchangeable straps or watch faces, to give customers a sense of personalization and ownership.\n","\n","#### Suggestion for pricing:\n","To address the issue of a high price point, we recommend the following:\n","\n","- Conduct a price elasticity analysis to determine the optimal price point for the smartwatch.\n","- Consider offering a premium version of the smartwatch with additional features or a higher-end design, while keeping the base model at a more competitive price point.\n","- Offer discounts or promotions to incentivize customers to purchase the smartwatch, such as a \"buy one get one free\" deal or a limited-time discount.\n","- Consider a subscription-based model, where customers pay a monthly or annual fee for access to premium features or services.\n","\n","#### Suggestion for marketing communications:\n","To address the issue of disappointing sales, we recommend the following:\n","\n","- Develop a targeted marketing campaign that highlights the unique features and benefits of the smartwatch, such as its ability to track fitness metrics or receive notifications.\n","- Utilize social media platforms to engage with customers and gather feedback on the product, while also promoting the smartwatch through influencer partnerships and sponsored content.\n","- Create a series of educational videos or blog posts that demonstrate the features and benefits of the smartwatch, such as how to use the built-in GPS or how to customize the watch face.\n","- Offer a satisfaction guarantee or a warranty program to alleviate concerns about the product's quality and value.\n"]}]},{"cell_type":"markdown","source":["Explanation:\n","\n","- `<Instructions>`: Sets the model's persona and primary objective.\n","\n","- `<Article>`: Contains the raw data to be analyzed.\n","\n","- `<Response_Format>`: Clearly outlines the desired structure of the output. This forces the model to organize its response systematically and address all specified points.\n","\n"],"metadata":{"id":"BzHT8XuQ-5En"}},{"cell_type":"markdown","source":["## Structured Output"],"metadata":{"id":"1-MIkua_qMkJ"}},{"cell_type":"markdown","source":["`CSV` is best reserved for situations where the data is exclusively flat and **tabular**, like a basic spreadsheet.\n","\n","`JSON` is the clear winner for most tasks today because it can handle **hierarchical and nested data**. This is essential for working with APIs, configurations, and any data that isn't a simple table. It also natively supports data types like integers, strings, and booleans, which simplifies processing."],"metadata":{"id":"HJ40UxIZqQe9"}},{"cell_type":"markdown","source":["### Output : CSV"],"metadata":{"id":"eI45ATexGx3I"}},{"cell_type":"code","source":["# Example: Structured output (CSV)\n","prompt = \"\"\"You are a helpful assistant.\n","**Task:** Convert the following customer list into a CSV string.\n","**Output Format:** The first row should contain the headers \"Name\" and \"City\".\n","The subsequent rows should contain the customer data, with values separated by commas.\n","Whole answer should be under the backtrick ```csv ... ```.\n","Response the final answer only.\n","**Data:**\n","- John Doe from New York\n","- Jane Smith from London\n","- Peter Jones from Tokyo\n","\"\"\"\n","\n","ai_msg_csv = llm.invoke(prompt)\n","print(\"Structured Output:\\n\", ai_msg_csv.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1N_Awr4qPtT","outputId":"cf2b0abc-cb21-4e0a-80a4-0278a6343131","executionInfo":{"status":"ok","timestamp":1770648046143,"user_tz":-420,"elapsed":484,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Structured Output:\n"," ```csv\n","Name,City\n","John Doe,New York\n","Jane Smith,London\n","Peter Jones,Tokyo\n","```\n"]}]},{"cell_type":"markdown","source":["#### Parsing CSV Output into a DataFrame"],"metadata":{"id":"snb2aS38F04e"}},{"cell_type":"markdown","source":["We used a regex pattern to find the ```csv``` content and convert them into a DataFrame."],"metadata":{"id":"Tpz49DBWF6Up"}},{"cell_type":"code","source":["import re\n","import pandas as pd\n","import io\n","\n","def csv_string_to_df(text: str) -> pd.DataFrame:\n","    \"\"\"\n","    Extracts CSV content from a string and converts it into a pandas DataFrame.\n","\n","    Args:\n","        text (str): The input string containing CSV content enclosed in ```csv...```.\n","\n","    Returns:\n","        pd.DataFrame: A pandas DataFrame containing the extracted data.\n","    \"\"\"\n","    # Use a regex pattern to find the content between the delimiters\n","    match = re.search(r'```csv\\s(.*?)```', text, re.DOTALL)\n","\n","    if match:\n","        # Extract the content from the first capturing group\n","        csv_content = match.group(1).strip()\n","\n","        # Use io.StringIO to treat the string as a file\n","        data = io.StringIO(csv_content)\n","\n","        # Read the \"file\" into a pandas DataFrame\n","        df = pd.read_csv(data)\n","\n","        return df\n","    else:\n","        # Return an empty DataFrame or raise an error if no match is found\n","        print(\"No CSV content found within ```csv...``` delimiters.\")\n","        return pd.DataFrame()"],"metadata":{"id":"9F0mecNaEi3f","executionInfo":{"status":"ok","timestamp":1770648046377,"user_tz":-420,"elapsed":233,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["csv_string_to_df(ai_msg_csv.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"rmEcEtk7GE8q","outputId":"6ab7a48b-3d50-4be9-c07d-2c882a566a22","executionInfo":{"status":"ok","timestamp":1770648046414,"user_tz":-420,"elapsed":36,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          Name      City\n","0     John Doe  New York\n","1   Jane Smith    London\n","2  Peter Jones     Tokyo"],"text/html":["\n","  <div id=\"df-8b25dcae-4f42-4d17-8cfe-47b8f2967809\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>City</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>John Doe</td>\n","      <td>New York</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jane Smith</td>\n","      <td>London</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Peter Jones</td>\n","      <td>Tokyo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b25dcae-4f42-4d17-8cfe-47b8f2967809')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8b25dcae-4f42-4d17-8cfe-47b8f2967809 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8b25dcae-4f42-4d17-8cfe-47b8f2967809');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"csv_string_to_df(ai_msg_csv\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"John Doe\",\n          \"Jane Smith\",\n          \"Peter Jones\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"New York\",\n          \"London\",\n          \"Tokyo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["### Output : JSON"],"metadata":{"id":"qUqbr39-G8kl"}},{"cell_type":"code","source":["# Example: Structured output (JSON)\n","prompt = \"\"\"\n","You are a helpful assistant.\n","For the given student record, return a JSON object with the following fields:\n","- name (string) → student’s full name\n","- age (integer) → student’s age\n","- scores (object) → nested dictionary with subject name as key and integer score as value\n","- extracurricular (array of strings) → list of activities\n","The whole answer must be under ```json ... ```.\n","Student Record:\n","Alice, 21 years old. Math = 85, English = 92. She joined Basketball and Drama Club.\n","\n","Answer:\n","Response the final answer only.\n","\"\"\"\n","\n","ai_msg_json = llm.invoke(prompt)\n","print(\"Structured Output:\\n\", ai_msg_json.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cce0eb19-e4c0-434d-ea47-920a689a1c27","id":"PkbM0hvuG8kl","executionInfo":{"status":"ok","timestamp":1770648046720,"user_tz":-420,"elapsed":292,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Structured Output:\n"," ```json\n","{\n","  \"name\": \"Alice\",\n","  \"age\": 21,\n","  \"scores\": {\n","    \"Math\": 85,\n","    \"English\": 92\n","  },\n","  \"extracurricular\": [\"Basketball\", \"Drama Club\"]\n","}\n","```\n"]}]},{"cell_type":"markdown","source":["#### Parsing JSON Output into Dict"],"metadata":{"id":"e6UZdGS6G8kl"}},{"cell_type":"markdown","source":["We used a regex pattern to find the ```csv``` content and convert them into a DataFrame."],"metadata":{"id":"pbYRVsTRG8kl"}},{"cell_type":"code","source":["import re\n","import json\n","\n","def json_string_to_dict(text: str):\n","    \"\"\"\n","    Extracts JSON content from a string enclosed in ```json...```\n","    and parses it into a Python dict or list.\n","\n","    Args:\n","        text (str): The input string containing JSON content enclosed in ```json...```.\n","\n","    Returns:\n","        dict or list: Parsed JSON object (Python dict or list).\n","    \"\"\"\n","    # Use regex to find JSON block\n","    match = re.search(r'```json\\s(.*?)```', text, re.DOTALL)\n","\n","    if match:\n","        # Extract JSON content\n","        json_content = match.group(1).strip()\n","\n","        try:\n","            return json.loads(json_content)\n","        except json.JSONDecodeError as e:\n","            print(\"Invalid JSON:\", e)\n","            return None\n","    else:\n","        print(\"No JSON content found within ```json...``` delimiters.\")\n","        return None"],"metadata":{"id":"mVl5noz0M8AX","executionInfo":{"status":"ok","timestamp":1770648046729,"user_tz":-420,"elapsed":46,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["dict_output = json_string_to_dict(ai_msg_json.content)\n","dict_output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUIY-djMM-P_","outputId":"6306257d-f07c-44ce-b314-275e28a9f306","executionInfo":{"status":"ok","timestamp":1770648046729,"user_tz":-420,"elapsed":28,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'name': 'Alice',\n"," 'age': 21,\n"," 'scores': {'Math': 85, 'English': 92},\n"," 'extracurricular': ['Basketball', 'Drama Club']}"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["dict_output['scores']['Math']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KjqbbnvNeE4","outputId":"2acac3ad-f49e-4cf1-f3b9-e3e079918844","executionInfo":{"status":"ok","timestamp":1770648046730,"user_tz":-420,"elapsed":25,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["85"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["### Output : Pydantic Schema"],"metadata":{"id":"QR96B7zq0pfm"}},{"cell_type":"markdown","source":["- LangChain supports structured outputs, **allowing us to bind a schema (dict / JSON Schema / Pydantic) to the model**\n","  - and enforce responses to follow the defined structure instead of relying only on prompt wording.\n","- ***However, complex output structures may still fail, so prompting and custom parsing function are still important in some cases.***\n","\n","Read more: [LangChain Docs – Structured Outputs](https://python.langchain.com/docs/concepts/structured_outputs/)\n"],"metadata":{"id":"V9xRrjgy09pD"}},{"cell_type":"code","source":["# pydantic schema\n","\n","# suppose that we want the output something like this :\n","'''{'name': 'Alice',\n"," 'age': 21,\n"," 'scores': {'Math': 85, 'English': 92},\n"," 'extracurricular': ['Basketball', 'Drama Club']}'''\n","\n","# we can defined class (data fields) like this\n","\n","from typing import Dict, List\n","from pydantic import BaseModel, Field\n","\n","class DesiredOutput(BaseModel):\n","    name: str = Field(description=\"Student's first name\")\n","    age: int = Field(description=\"Age in years\")\n","    extracurricular: List[str] = Field(description=\"List of activities/clubs\")\n","\n","    #subject_scores: Dict[str, int] = Field(description=\"Key = subject, Value = scores (as a JSON object)\")\n","\n","    # This line cause an error. / Complex Data Structure (uncomment if you want to test it)"],"metadata":{"id":"DLSKUOVy0uN2","executionInfo":{"status":"ok","timestamp":1770648046730,"user_tz":-420,"elapsed":13,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Wrap LLM so it returns a DesiredOutput object directly\n","structured_llm = llm.with_structured_output(DesiredOutput)"],"metadata":{"id":"LNMNByvN27fS","executionInfo":{"status":"ok","timestamp":1770648046753,"user_tz":-420,"elapsed":34,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["prompt = \"\"\"\n","You are a helpful assistant.\n","For the given student record, extract informations\n","\n","Student Record:\n","Alice, 21 years old. Math = 85, English = 92. She joined Basketball and Drama Club.\n","\n","Answer:\n","\"\"\"\n","\n","\n","# Generate output\n","results = structured_llm.invoke(prompt)\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJc0JMrS3pld","outputId":"eefaacb6-7c8f-425a-fa51-d8df721c1903","executionInfo":{"status":"ok","timestamp":1770648047023,"user_tz":-420,"elapsed":270,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DesiredOutput(name='Alice', age=21, extracurricular=['Basketball', 'Drama Club'])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["results.model_dump_json()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"fqArflod__Q4","outputId":"b0264c24-c1cc-4af7-b336-b40abdd285ef","executionInfo":{"status":"ok","timestamp":1770648047023,"user_tz":-420,"elapsed":60,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'{\"name\":\"Alice\",\"age\":21,\"extracurricular\":[\"Basketball\",\"Drama Club\"]}'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["## Boundary Condition\n","- **Don't know, don't guess**  \n","  Instruct the model to answer *\"I don’t know\"* if the information is unknown or unverifiable.  \n","  → Helps prevent the model from attempting to answer overly difficult or specific open-ended questions.  \n","  > Note: This depends on the **use case** — but in scenarios where we *don’t want the model to attempt an uncertain answer*, this condition is very useful.\n","\n","- **Output Format Remarking**  \n","  Explicitly remind the model about the required output format.  \n","  → e.g., *\"Don’t give any additional explanation, just output [format] only.\"*"],"metadata":{"id":"3xeHCngFhtAK"}},{"cell_type":"code","source":["# Example 1: Without boundary condition\n","prompt = \"\"\"\n","What are the details of the announcement from the Meteorological Department, Announcement No. 2/2025, regarding ‘Measures to Cope with the Early Arrival of Summer Storms’?\n","\"\"\"\n","\n","ai_msg = llm.invoke(prompt)\n","print(\"Without boundary condition:\\n\", ai_msg.content)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVMrB0dcd1ic","outputId":"09881170-efef-491a-843b-2943b729c27d","executionInfo":{"status":"ok","timestamp":1770648047198,"user_tz":-420,"elapsed":186,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Without boundary condition:\n"," I'm unable to verify the details of the announcement from the Meteorological Department, Announcement No. 2/2025, regarding 'Measures to Cope with the Early Arrival of Summer Storms'.\n"]}]},{"cell_type":"markdown","source":["**Key Takeaways**:\n","- Without boundary conditions, an LLM will still attempt to generate an answer — sometimes hallucinating content, and other times making an estimated guess while recognizing its own uncertainty.\n","- If you want to avoid such cases, define clear boundary conditions that tell the LLM to respond with `“I don’t know”` or another `concise fallback` instead of producing uncertain or fabricated answers.\n","- This keeps your system consistent and predictable."],"metadata":{"id":"culOGTStHBct"}},{"cell_type":"code","source":["# Example 2: With boundary condition\n","prompt = \"\"\"\n","What are the details of the announcement from the Meteorological Department, Announcement No. 2/2025, regarding ‘Measures to Cope with the Early Arrival of Summer Storms’?\n","\n","If the answer is not known or cannot be verified, just reply: `None`.\n","\"\"\"\n","\n","ai_msg = llm.invoke(prompt)\n","print(\"With boundary condition:\\n\", ai_msg.content)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zFYUTpPeyR4v","outputId":"8f574829-971a-4756-9be0-0f929f9184e1","executionInfo":{"status":"ok","timestamp":1770648047322,"user_tz":-420,"elapsed":145,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["With boundary condition:\n"," None.\n"]}]},{"cell_type":"markdown","source":["## Prompt Template\n","\n","Prompt templates offer several benefits:\n","\n","- **Consistency**: Ensure a consistent structure for your prompts across multiple interactions\n","- **Efficiency**: Easily swap out variable content without rewriting the entire prompt\n","- **Testability**: Quickly test different inputs and edge cases by changing only the variable portion\n","- **Scalability***: Simplify prompt management as your application grows in complexity\n","- **Version control**: Easily track changes to your prompt structure over time by keeping tabs only on the core part of your prompt, separate from dynamic inputs"],"metadata":{"id":"UyIZT0fiz-x9"}},{"cell_type":"markdown","source":["### Example: Prompt Template in a Loop (Task: Sentiment Analysis)\n","\n","Example Task: **Sentiment Analysis**\n","\n","We used a prompt template with the approach **“run in a loop + change only variables”**.  \n","This demonstrates how prompt templates cover several benefits at once:\n","\n","- **Consistency**: Every iteration uses the same prompt structure.  \n","- **Efficiency**: Only the variable `{text}` changes in each loop.  \n","- **Testability**: Multiple inputs can be tested quickly by swapping variable values.  \n","- **Scalability**: The same template can be applied to a larger dataset without modification.  \n","- **Version Control**: Easily track prompt versions against results.\n","\n","\n"],"metadata":{"id":"3R-tfOsrRG7A"}},{"cell_type":"code","source":["!wget https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt"],"metadata":{"id":"4ryOL6guq0C-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3d57ae3b-caec-43db-f44b-83ef91258127","executionInfo":{"status":"ok","timestamp":1770648048187,"user_tz":-420,"elapsed":864,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["--2026-02-09 14:40:48--  https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt [following]\n","--2026-02-09 14:40:48--  https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 122071 (119K) [text/plain]\n","Saving to: ‘dev.txt’\n","\n","dev.txt             100%[===================>] 119.21K  --.-KB/s    in 0.01s   \n","\n","2026-02-09 14:40:49 (9.79 MB/s) - ‘dev.txt’ saved [122071/122071]\n","\n"]}]},{"cell_type":"code","source":["def read_xy_data(filename: str) -> tuple[list[str], list[int]]:\n","    x_data = []\n","    y_data = []\n","    with open(filename, 'r') as f:\n","        for line in f:\n","            label, text = line.strip().split(' ||| ')\n","            x_data.append(text)\n","            y_data.append(int(label))\n","    return x_data, y_data"],"metadata":{"id":"fXa_FpBL6zt2","executionInfo":{"status":"ok","timestamp":1770648048208,"user_tz":-420,"elapsed":20,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["x_test, y_test = read_xy_data('dev.txt')\n","x_test, y_test = x_test[:10], y_test[:10] # small size for quick testing"],"metadata":{"id":"IbNrlgaWRVz_","executionInfo":{"status":"ok","timestamp":1770648048219,"user_tz":-420,"elapsed":2,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["For sentiment analysis, we will be using the following prompt:\n","\n","```\n","Analyse the sentiment of the following text: ```text```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","```\n","LLMs nowaday usually have chain-of-thought baked in so they usually will output their reasoning before answering.\n","\n","- It is important to tell the model not to output their explanation by including `**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","`\n","- Otherwise, it will not be easy to programmatically use the outputs.\n","Alternatively, you can use structured outputs `(see table of contents -> Structured Output)` for ease of parsing."],"metadata":{"id":"6EU6prW_oeTF"}},{"cell_type":"code","source":["prompt_template = \"\"\"\n","Analyse the sentiment of the following text: ```{x_input}```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\"\"\""],"metadata":{"id":"y3wwc3vJiiJO","executionInfo":{"status":"ok","timestamp":1770648048314,"user_tz":-420,"elapsed":87,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["from tqdm.notebook import tqdm"],"metadata":{"id":"Py85PRxuXwjN","executionInfo":{"status":"ok","timestamp":1770648048314,"user_tz":-420,"elapsed":65,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["import time\n","from tqdm.notebook import tqdm\n","\n","output = []\n","for sent in tqdm(x_test):\n","   try:\n","      prompt_filled = prompt_template.format(x_input=sent)\n","      print('prompt:', prompt_filled) # debugging\n","      output_res = llm.invoke(prompt_filled).content.strip()\n","      print('response:', output_res) # debugging\n","      print('--'*20)\n","      output.append(int(output_res))\n","      time.sleep(2) # Adding a 2-second delay to avoid rate limit error\n","   except:\n","      output.append(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a586e130729a4594a36a5c910cd19f28","7dce6349ce28416a9cc4b32f5593a3f2","75e1164c2e204b2da07ed040c5d507f5","2574f0eccc4b424288b4ba2a79575c6c","91a4d91f0b604ac4b76697cd09240a62","1a36a2b9b7a441419806e1fb865c1c04","4d841c3f700241328a251ff20db6fa6f","0248a72dbcd64bb4990acc232d6c56a9","f292ca2b0e22459186fe6ca4393ba01c","2a6a90d8d9f44733a88d194ddeb48923","7514e797200442f2b47542b6a0d42ca2"]},"id":"QFFPVtwT9rjZ","outputId":"b0e17f4b-09de-4cfc-f6bb-d94c2384b9d2","executionInfo":{"status":"ok","timestamp":1770648070161,"user_tz":-420,"elapsed":21908,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a586e130729a4594a36a5c910cd19f28"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["prompt: \n","Analyse the sentiment of the following text: ```It 's a lovely film with lovely performances by Buy and Accorsi .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```No one goes unindicted here , which is probably for the best .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```And if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```A warm , funny , engaging film .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Uses sharp humor and insight into human nature to examine class conflict , adolescent yearning , the roots of friendship and sexual identity .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Half Submarine flick , Half Ghost Story , All in one criminally neglected film```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Entertains by providing good , lively company .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Dazzles with its fully-written characters , its determined stylishness -LRB- which always relates to characters and story -RRB- and Johnny Dankworth 's best soundtrack in years .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Visually imaginative , thematically instructive and thoroughly delightful , it takes us on a roller-coaster ride from innocence to experience without even a hint of that typical kiddie-flick sentimentality .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Nothing 's at stake , just a twisty double-cross you can smell a mile away -- still , the derivative Nine Queens is lots of fun .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test, output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dp7ZS8hKVRb8","outputId":"5690108e-8ac9-4513-c885-86a661876693","executionInfo":{"status":"ok","timestamp":1770648071169,"user_tz":-420,"elapsed":1008,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["## Additional: Temperature Setting"],"metadata":{"id":"_AryYrz0F-Pr"}},{"cell_type":"markdown","source":["Settings to keep in mind\n","\n","- Temperature is an important parameter to consider.\n","  - Keep it low if you are looking for exact or deterministic answers.\n","  - Keep it high if you are looking for more diverse or creative responses.\n","\n","> In all the previous examples, we only set up the LLM once, and the parameter was fixed as Temperature = 0\n","\n","This means every example so far was generated with a deterministic setting (no randomness)."],"metadata":{"id":"oNWq0plMFcEV"}},{"cell_type":"markdown","source":["### Approach 1 : Gemini"],"metadata":{"id":"26-zG4kznPuU"}},{"cell_type":"markdown","source":["Temperature Range for Gemini-2.5-flash : 0-2 (default 1)\n","\n",">Ref: https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash"],"metadata":{"id":"mJA6w0hAdyxg"}},{"cell_type":"code","source":["# from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","# llm_low_temp = ChatGoogleGenerativeAI(\n","#     model=\"gemini-2.5-flash\",\n","#     temperature=0,\n","#     max_tokens=None,\n","#     timeout=None,\n","#     max_retries=2,\n","#     # other params...\n","# )"],"metadata":{"id":"1LscvX8fjVzY","executionInfo":{"status":"ok","timestamp":1770648071171,"user_tz":-420,"elapsed":1,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# llm_high_temp = ChatGoogleGenerativeAI(\n","#     model=\"gemini-2.5-flash\",\n","#     temperature=2,\n","#     max_tokens=None,\n","#     timeout=None,\n","#     max_retries=2,\n","#     # other params...\n","# )"],"metadata":{"id":"gx4NPLujeWZN","executionInfo":{"status":"ok","timestamp":1770648071189,"user_tz":-420,"elapsed":16,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# # llm_low_temp\n","# prompt = \"Write one slogan for a mobile banking application. Just only answer the slogan without additional suggestions\"\n","# for rnd in range(3):\n","#   try:\n","#     output_res = llm_low_temp.invoke(prompt).content.strip()\n","#     print(f\"Round {rnd+1} | response:\", output_res)\n","#   except Exception as e:\n","#     print(f\"Round {rnd+1} | Error:\", e)\n","\n","#   print(\"--\"*30)\n","#   time.sleep(2)"],"metadata":{"id":"Kbra6aNZgtM3","executionInfo":{"status":"ok","timestamp":1770648071190,"user_tz":-420,"elapsed":5,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# # llm_high_temp\n","# prompt = \"Write one slogan for a mobile banking application. Just only answer the slogan without additional suggestions\"\n","# for rnd in range(3):\n","#   try:\n","#     output_res = llm_high_temp.invoke(prompt).content.strip()\n","#     print(f\"Round {rnd+1} | response:\", output_res)\n","#   except Exception as e:\n","#     print(f\"Round {rnd+1} | Error:\", e)\n","\n","#   print(\"--\"*30)\n","#   time.sleep(2)"],"metadata":{"id":"dAlpPN-nhd4w","executionInfo":{"status":"ok","timestamp":1770648071193,"user_tz":-420,"elapsed":1,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["### Approach 2 : Groq"],"metadata":{"id":"RsY7T_wVnVfO"}},{"cell_type":"code","source":["llm_low_temp = ChatGroq(\n","    model=\"llama-3.1-8b-instant\", # can change\n","    temperature=0,\n","    max_tokens=None,\n","    timeout=None,\n","    max_retries=2,\n",")"],"metadata":{"id":"wvmj7HNYnVfO","executionInfo":{"status":"ok","timestamp":1770648071306,"user_tz":-420,"elapsed":112,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["llm_high_temp = ChatGroq(\n","    model=\"llama-3.1-8b-instant\", # can change\n","    temperature=0.9,\n","    max_tokens=None,\n","    timeout=None,\n","    max_retries=2,\n",")"],"metadata":{"id":"Dl-SlB7anVfO","executionInfo":{"status":"ok","timestamp":1770648071430,"user_tz":-420,"elapsed":123,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# low_temp\n","prompt = \"Write one slogan for a mobile banking application. Just only answer the slogan without additional suggestions\"\n","for rnd in range(3):\n","  try:\n","    output_res = llm_low_temp.invoke(prompt).content.strip()\n","    print(f\"Round {rnd+1} | response:\", output_res)\n","  except Exception as e:\n","    print(f\"Round {rnd+1} | Error:\", e)\n","\n","  print(\"--\"*30)\n","  time.sleep(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d4a8f630-fcda-45d0-a3c7-2c033ca981ed","executionInfo":{"status":"ok","timestamp":1770648077990,"user_tz":-420,"elapsed":6559,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}},"id":"1Z063qNdnVfP"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Round 1 | response: \"Bank on the go, wherever you grow.\"\n","------------------------------------------------------------\n","Round 2 | response: \"Bank on the go, wherever you grow.\"\n","------------------------------------------------------------\n","Round 3 | response: \"Bank on the go, wherever you grow.\"\n","------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["# llm_high_temp\n","prompt = \"Write one slogan for a mobile banking application. Just only answer the slogan without additional suggestions\"\n","for rnd in range(3):\n","  try:\n","    output_res = llm_high_temp.invoke(prompt).content.strip()\n","    print(f\"Round {rnd+1} | response:\", output_res)\n","  except Exception as e:\n","    print(f\"Round {rnd+1} | Error:\", e)\n","\n","  print(\"--\"*30)\n","  time.sleep(2) # Adding a 2-second delay to avoid rate limit error"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a6a828f4-0723-4e71-f490-0d5907a8ac00","executionInfo":{"status":"ok","timestamp":1770648085238,"user_tz":-420,"elapsed":7247,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}},"id":"gCvrrT8wnVfP"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Round 1 | response: \"Bank on the move, not in line.\"\n","------------------------------------------------------------\n","Round 2 | response: \"Banking at your fingertips, anywhere in life.\"\n","------------------------------------------------------------\n","Round 3 | response: \"Bank on the move, wherever you go.\"\n","------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["Summary\n","\n","- Low temp → Reliable, consistent outputs. Useful for classification, extraction, or when you want reproducibility.\n","- High temp → Diverse, creative slogans. Useful for brainstorming, ideation, or when multiple fresh options are desired."],"metadata":{"id":"jp0VKZZVhzsD"}}]}
>>>>>>> upstream/main
