{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1QiG4zWZdW2uli2gP3kefLb-J6AKcGduq","timestamp":1762917830714},{"file_id":"1QxDB72JWQWjrFlUKwfx_i-f84wGmS87T","timestamp":1762916838842},{"file_id":"https://github.com/pvateekul/2190513_DS-ICE_2025s1/blob/main/code/Week12_GenerativeAI/7_2_LLM_Prompt_Engineering_Basic_LangChain.ipynb","timestamp":1762916612684}],"toc_visible":true,"collapsed_sections":["gac5oO3pj2Mj"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9b4f7e1961ba42df88814dda0b392320":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_990e58c5061f48a5839b27be1683137d","IPY_MODEL_e3b61235ebcc4f1fbea597a5845e138f","IPY_MODEL_4ccce19bc99d4cd18ce4e9a0f6b838be"],"layout":"IPY_MODEL_ae155ca74bf24eb58e09bbd762d9d58f"}},"990e58c5061f48a5839b27be1683137d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9579b4aa97ba4c8fbf0cb7a2ad1f06f8","placeholder":"‚Äã","style":"IPY_MODEL_185000b1d0a541fea9a2fd9d154e10e5","value":"100%"}},"e3b61235ebcc4f1fbea597a5845e138f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a37adc5b3f54dfd819866a7ac67969d","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c5d7c4dc79054245834085755db937d0","value":10}},"4ccce19bc99d4cd18ce4e9a0f6b838be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cbe04e520a6436db7b638c506acd0c9","placeholder":"‚Äã","style":"IPY_MODEL_314ee287411948e6a7e39be27d040006","value":"‚Äá10/10‚Äá[00:21&lt;00:00,‚Äá‚Äá2.10s/it]"}},"ae155ca74bf24eb58e09bbd762d9d58f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9579b4aa97ba4c8fbf0cb7a2ad1f06f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"185000b1d0a541fea9a2fd9d154e10e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a37adc5b3f54dfd819866a7ac67969d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5d7c4dc79054245834085755db937d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1cbe04e520a6436db7b638c506acd0c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"314ee287411948e6a7e39be27d040006":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["Due to the current situation (`Updated 09/02/2026`),\n","\n","- Google Gemini has reduced the rate limits for several models, such as `gemini-2.5-flash` and `gemini-3-flash` (text models used in Colab notebooks), to a **limit of 20 Requests Per Day (RPD)**.\n","\n","- To continue using these models seamlessly with sufficient rate limits, it is necessary to upgrade to the **pay-as-you-go tier** (link a Billing Account).\n","  - üëâ You can learn how to do this here: [https://ai.google.dev/gemini-api/docs/billing](https://ai.google.dev/gemini-api/docs/billing)\n","\n","- Alternatively, you can follow the Groq API approach described below.\n"],"metadata":{"id":"6bLkLM6QcD8m"}},{"cell_type":"markdown","source":["# Overall of this notebook"],"metadata":{"id":"VXSQW2RpFSYe"}},{"cell_type":"markdown","source":["Most of concepts and codes are adapted from\n","- https://github.com/dair-ai/Prompt-Engineering-Guide\n","- https://ai.google.dev/gemini-api/docs/prompting-strategies\n","- https://myframework.net/icio-ai-prompt-framework/"],"metadata":{"id":"uwrZRFXNFj74"}},{"cell_type":"markdown","source":["# Setting environments and model setup"],"metadata":{"id":"tXNDggfzh28Q"}},{"cell_type":"markdown","source":["## Approach 1: Gemini"],"metadata":{"id":"gac5oO3pj2Mj"}},{"cell_type":"code","source":["%%capture\n","!pip install -qU langchain-google-genai"],"metadata":{"id":"ZRhhli6S3UkP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Request for Google API KEY here : https://aistudio.google.com/app/apikey"],"metadata":{"id":"3sT4diEh3gUJ"}},{"cell_type":"code","source":["from getpass import getpass\n","import os\n","\n","if \"GOOGLE_API_KEY\" not in os.environ:\n","    os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google AI API key: \")"],"metadata":{"id":"wPsljCqyNPnt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"75a1825a-26ce-44a7-84bb-e584b976695c","executionInfo":{"status":"ok","timestamp":1762917923604,"user_tz":-420,"elapsed":1495,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Google AI API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"]}]},{"cell_type":"code","source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-2.5-flash\",\n","    temperature=0,\n","    max_tokens=None,\n","    timeout=None,\n","    max_retries=2,\n","    # other params...\n",")"],"metadata":{"id":"sbi2CAPqOHef"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Approach 2: Groq API"],"metadata":{"id":"t34XEcouj72D"}},{"cell_type":"markdown","source":["\n","However, we still have an **alternative** that can be used via a free-tier API: **Groq API** (compatible with LangChain). This does not require linking a credit card and offers several models, such as:\n","\n","- `llama-3.1-8b-instant` (Rate limit: 30 RPM, 14.4K RPD) *RPM = Requests Per Minute, RPD = Requests Per Day\n","- `llama-3.3-70b-versatile` (Rate limit: 30 RPM, 1K RPD)\n","- Other available models: https://console.groq.com/settings/limits\n","\n","*(RPM = Requests Per Minute, TPM = Tokens Per Minute)*\n","\n","üëâ You can sign up and get your API Key here: [https://console.groq.com/keys](https://console.groq.com/keys)\n"],"metadata":{"id":"mPDA4a1xgsHH"}},{"cell_type":"code","source":["!pip install -qU langchain-groq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4GfwFsZhUBA","executionInfo":{"status":"ok","timestamp":1770626717391,"user_tz":-420,"elapsed":5896,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}},"outputId":"898f16cd-52b0-4359-9571-d2718b5bd4ad"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/137.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import getpass\n","import os\n","\n","os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API key: \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J_VGYtIuiANL","executionInfo":{"status":"ok","timestamp":1770626723891,"user_tz":-420,"elapsed":990,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}},"outputId":"1ca88c8f-aa7e-49be-972d-f2e2bd3676ba"},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Groq API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"]}]},{"cell_type":"code","source":["from langchain_groq import ChatGroq\n","\n","llm = ChatGroq(\n","    model=\"llama-3.1-8b-instant\", # can change\n","    temperature=0,\n","    max_tokens=None,\n","    timeout=None,\n","    max_retries=2,\n",")"],"metadata":{"id":"yucHEIvuhmYo","executionInfo":{"status":"ok","timestamp":1770626742349,"user_tz":-420,"elapsed":16335,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Basic"],"metadata":{"id":"enmt8H4Shngs"}},{"cell_type":"markdown","source":["## System Prompt / User Prompt"],"metadata":{"id":"rF6TFz-mFEK-"}},{"cell_type":"markdown","source":["`System Prompt`:\n","\n","The system prompt establishes the overall context, persona, and behavioral guidelines for the LLM. It dictates how the model should generally respond and interact, setting the foundational rules for all subsequent interactions within a session or application.\n","\n","`User Prompt (Human)`:\n","\n","  The user prompt is the specific query or instruction provided by the user to the LLM. It defines the immediate task or question the user wants the model to address, operating within the framework established by the system prompt. example\n"],"metadata":{"id":"6Xuv336sgo_2"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYdX-hTxE_vg","outputId":"e0239dd4-e69e-4598-bd2f-fe750ebdb4ca","executionInfo":{"status":"ok","timestamp":1770626751569,"user_tz":-420,"elapsed":333,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Regular exercise is crucial for maintaining physical and mental health, as it reduces the risk of chronic diseases, improves cardiovascular function, enhances cognitive function, and promotes overall well-being.\n"]}],"source":["# Demo 1: System - Health Scientist / User - Explain the importance of exercise\n","messages = [\n","    (\"system\", \"You are a health scientist who always provides factual and evidence-based answers.\"),\n","    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n","]\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"]},{"cell_type":"code","source":["# Demo 2: Syetem - Elderly Person Complaining / User - Explain the importance of exercise\n","messages = [\n","    (\"system\", \"You are an elderly person who often complains.\"),\n","    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n","]\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_y6fndhCsxL9","outputId":"7ecfc649-05ea-44b1-dd78-7bfe2965990e","executionInfo":{"status":"ok","timestamp":1770626754212,"user_tz":-420,"elapsed":247,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["*sigh* Fine, exercise is supposed to be good for you, keeps the old bones from creaking too much and the heart from giving out, but I swear, it's a chore.\n"]}]},{"cell_type":"code","source":["# Demo 3: System - Mother Explaining to a 5-year-old / User - Explain the importance of exercise\n","messages = [\n","    (\"system\", \"You are a mother who needs to answer questions from a 5-year-old child, always explaining complex topics in the simplest way possible.\"),\n","    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n","]\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2epKy8w5sync","outputId":"3889d5dd-710a-4d5a-8eba-251dcb1184d2","executionInfo":{"status":"ok","timestamp":1770626771290,"user_tz":-420,"elapsed":253,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Exercise is like giving our bodies a big hug from the inside out, making us strong and healthy so we can run, play, and have lots of fun!\n"]}]},{"cell_type":"code","source":["# Demo 4: Professional Assistant (Python factorial)\n","messages = [\n","    (\"system\", \"You are a helpful and informative assistant. Your responses should be clear, concise, and professional. Avoid making assumptions and always ask for clarification if a user's request is ambiguous.\"),\n","    (\"human\", \"Write a Python function that calculates the factorial of a given number.\"),\n","]\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lblLbxY2s2An","outputId":"d15d8356-f52e-4dee-ac0f-2f6679370af0","executionInfo":{"status":"ok","timestamp":1770626779053,"user_tz":-420,"elapsed":535,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["**Calculating the Factorial of a Number in Python**\n","=====================================================\n","\n","Here's a simple Python function that calculates the factorial of a given number using recursion and iteration:\n","\n","### Recursive Implementation\n","\n","```python\n","def factorial_recursive(n):\n","    \"\"\"\n","    Calculate the factorial of a number using recursion.\n","\n","    Args:\n","        n (int): The number to calculate the factorial for.\n","\n","    Returns:\n","        int: The factorial of the given number.\n","\n","    Raises:\n","        ValueError: If n is a negative integer.\n","    \"\"\"\n","    if not isinstance(n, int):\n","        raise TypeError(\"Input must be an integer.\")\n","    if n < 0:\n","        raise ValueError(\"Input must be a non-negative integer.\")\n","    elif n == 0 or n == 1:\n","        return 1\n","    else:\n","        return n * factorial_recursive(n - 1)\n","```\n","\n","### Iterative Implementation\n","\n","```python\n","def factorial_iterative(n):\n","    \"\"\"\n","    Calculate the factorial of a number using iteration.\n","\n","    Args:\n","        n (int): The number to calculate the factorial for.\n","\n","    Returns:\n","        int: The factorial of the given number.\n","\n","    Raises:\n","        ValueError: If n is a negative integer.\n","    \"\"\"\n","    if not isinstance(n, int):\n","        raise TypeError(\"Input must be an integer.\")\n","    if n < 0:\n","        raise ValueError(\"Input must be a non-negative integer.\")\n","    result = 1\n","    for i in range(1, n + 1):\n","        result *= i\n","    return result\n","```\n","\n","### Example Usage\n","\n","```python\n","print(factorial_recursive(5))  # Output: 120\n","print(factorial_iterative(5))  # Output: 120\n","```\n","\n","Both functions take an integer `n` as input and return the factorial of `n`. The recursive implementation uses a recursive function call to calculate the factorial, while the iterative implementation uses a loop to calculate the factorial. The functions also include input validation to ensure that the input is a non-negative integer.\n"]}]},{"cell_type":"markdown","source":["## User Prompt Framework - ICIO"],"metadata":{"id":"8PNPxY_VFH5C"}},{"cell_type":"markdown","source":["The ICIO framework is a simple and practical method that **helps you structure your prompts** step by step.\n","- `Instruction (I)` --> What do you want the AI to do?\n","\n","  - The instruction should be specific and direct. A clear task helps the AI give you the right kind of output.\n","- `Context (C)` --> Give background information. Why are you doing this task? What‚Äôs the situation?\n","\n","  - Context helps the AI better understand your purpose and tone.\n","  - ***Optional, but nice to have.***\n","\n","- `Input (I)` --> What exact text or data should the AI process?\n","  - Provide the content the AI needs to work with.\n","  - Without input data, the AI may guess or go off track. Be clear and complete.\n","\n","- `Output (O)` --> Set the style or format of the output. What should the response look like? What tone or structure do you expect?\n","  - This helps guide the AI to produce the kind of result you want."],"metadata":{"id":"fMZNMsDQFL2a"}},{"cell_type":"code","source":["# Example A: Customer Feedback Summary\n","\n","# ICIO fields\n","instruction = \"Summarize customer opinions.\"\n","context = \"For the product development team to consider improvements in the next version.\"\n","input_text = (\n","    \"Many customers like the battery lasting up to 3 days, which is much better than the older version. \"\n","    \"The AMOLED screen provides vibrant colors and is clearly visible even under bright sunlight. \"\n","    \"However, some users reported that Bluetooth connections with certain headphones often drop. \"\n","    \"The sleep tracking system is also not very accurate and sometimes fails to record data. \"\n","    \"Additionally, customers would like to see a blood pressure monitoring function added.\"\n",")\n","output_format = 'Summarize into a table with 3 columns: \"Feature\", \"Status (Good/Needs Improvement/Requested)\", \"Notes\".'\n","\n","# Create messages\n","messages = [\n","    (\"system\", \"You are a product analyst who summarizes customer feedback into clear, structured tables for business teams.\"),\n","    (\"human\",\n","     f\"{instruction}\\n\"\n","     f\"{context}\\n\"\n","     f\"{input_text}\\n\"\n","     f\"{output_format}\"\n","    ),\n","]\n","\n","# Invoke model\n","ai_msg = llm.invoke(messages)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdJiPsAhm1F7","outputId":"ef3b50ac-26f6-4f14-fe6d-fb5cd1122058","executionInfo":{"status":"ok","timestamp":1770626793031,"user_tz":-420,"elapsed":715,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Here's a summary of customer opinions in a table format:\n","\n","| Feature | Status | Notes |\n","| --- | --- | --- |\n","| Battery Life | Good | Lasts up to 3 days, an improvement from the older version |\n","| AMOLED Screen | Good | Provides vibrant colors and is visible under bright sunlight |\n","| Bluetooth Connectivity | Needs Improvement | Often drops connection with certain headphones |\n","| Sleep Tracking System | Needs Improvement | Not very accurate and sometimes fails to record data |\n","| Blood Pressure Monitoring | Requested | Customers would like to see this feature added |\n"]}]},{"cell_type":"markdown","source":["***To summarize, recognizing ICIO when prompting helps ensure the prompt is complete and clear, and that the LLM provides the desired output.***"],"metadata":{"id":"m7g0kOfg4xdy"}},{"cell_type":"markdown","source":["## Combine"],"metadata":{"id":"9hTlvQdLAWUO"}},{"cell_type":"markdown","source":["Note:\n","  - In practice, many modern prompts don't separate system and user instructions. Instead, they combine them into a single, comprehensive prompt.\n","  - This approach is effective because today's large language models are skilled at understanding and following complex, structured instructions.\n","  - You can define the model's persona, give it specific instructions, and provide the necessary data all within one prompt."],"metadata":{"id":"VnE7OTnc_uWc"}},{"cell_type":"code","source":["# Example B: Customer Feedback Summary (Single Prompt)\n","\n","prompt = '''\n","You are a product analyst who summarizes customer feedback into clear, structured tables for business teams.\n","Summarize customer opinions for the product development team to consider improvements in the next version.\n","Customer Opinions:\n","    \"Many customers like the battery lasting up to 3 days, which is much better than the older version. \"\n","    \"The AMOLED screen provides vibrant colors and is clearly visible even under bright sunlight. \"\n","    \"However, some users reported that Bluetooth connections with certain headphones often drop. \"\n","    \"The sleep tracking system is also not very accurate and sometimes fails to record data. \"\n","    \"Additionally, customers would like to see a blood pressure monitoring function added.\"\n","Output: Summarize into a table with 3 columns: \"Feature\", \"Status (Good/Needs Improvement/Requested)\", \"Notes\".\n","'''\n","\n","# Invoke model\n","ai_msg = llm.invoke(prompt)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AkndWCsAOdn","outputId":"a57746c9-b09b-411a-9fc0-04815134fbe9","executionInfo":{"status":"ok","timestamp":1770626820703,"user_tz":-420,"elapsed":336,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["**Customer Feedback Summary Table**\n","\n","| Feature | Status | Notes |\n","| --- | --- | --- |\n","| Battery Life | Good | Lasts up to 3 days, an improvement from the older version |\n","| AMOLED Screen | Good | Provides vibrant colors and is visible under bright sunlight |\n","| Bluetooth Connectivity | Needs Improvement | Drops connection with certain headphones |\n","| Sleep Tracking System | Needs Improvement | Not very accurate and sometimes fails to record data |\n","| Blood Pressure Monitoring | Requested | Customers would like to see this feature added |\n"]}]},{"cell_type":"markdown","source":["## Structured Input"],"metadata":{"id":"mKdBOwfBnlDX"}},{"cell_type":"markdown","source":["In prompt engineering, **structured input** helps guide the LLM to focus on exactly what we want.  \n","\n","One common technique is using **delimiters** (special symbols or markers) to clearly separate instructions, context, and input data.\n","\n","\n","Why use delimiters?\n","- They **reduce ambiguity** ‚Üí the model doesn‚Äôt ‚Äúguess‚Äù where instructions or content begin/end.  \n","- They **minimize misinterpretation** ‚Üí the model treats the content inside delimiters as a defined block.  \n","- They are especially useful when prompts are **long, multi-part, or contain different types of information**.\n","---\n","\n","Examples of delimiters\n","\n","You can use different symbols such as:\n","- Triple dashes (---)\n","- Triple hashtags (###)\n","- Triple backticks: \\`\\`\\` ... \\`\\`\\`\n","- Triple quotes: \"\"\" ... \"\"\"\n","- Angle brackets: < ... >\n","- Tags: `<instruction> ... </instruction>`"],"metadata":{"id":"H3oDxvd0p0Hz"}},{"cell_type":"code","source":["# The raw text to be summarized\n","text = \"\"\"\n","In the digital age, online marketing has become the cornerstone of businesses of all sizes, offering a broad reach to consumers at a lower cost than traditional marketing.\n","Popular online marketing tools include SEO (Search Engine Optimization), Social Media Marketing, and high-quality Content Marketing.\n","Leveraging data analytics also helps businesses analyze customer behavior and refine their strategies effectively.\n","\"\"\"\n","\n","# The prompt using delimiters (triple backticks ```)\n","prompt = f\"\"\"You are a helpful assistant.\n","Summarize the text within the triple backticks concisely, in no more than two sentences.\n","\n","```{text}```\n","\"\"\"\n","\n","ai_msg = llm.invoke(prompt)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0We1kF19Tea","outputId":"87f8d8c1-af53-4c19-a9e3-e6f50b0ae89c","executionInfo":{"status":"ok","timestamp":1770626828830,"user_tz":-420,"elapsed":235,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Online marketing has become a cornerstone for businesses, offering a broad reach at a lower cost than traditional marketing. Key tools include SEO, social media marketing, content marketing, and data analytics to refine strategies.\n"]}]},{"cell_type":"code","source":["prompt = f\"\"\"\n","<Instructions>\n","You are a marketing expert. Analyze the article within <Article> and provide recommendations based on the topics outlined in <Response_Format>.\n","</Instructions>\n","\n","<Article>\n","Our company recently launched a new smartwatch, but sales have been disappointing. Most customers say the features aren't unique compared to competitors, and the price is too high for the value they receive.\n","</Article>\n","\n","<Response_Format>\n","### Problem Analysis:\n","- [Summary of main issues]\n","\n","### Strategic Recommendations:\n","- [Suggestion for the product]\n","- [Suggestion for pricing]\n","- [Suggestion for marketing communications]\n","</Response_Format>\n","\"\"\"\n","\n","ai_msg = llm.invoke(prompt)\n","print(ai_msg.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jlZpQYyQ97Zu","outputId":"9be804b6-5728-44a5-8c04-69e98886051a","executionInfo":{"status":"ok","timestamp":1770626844406,"user_tz":-420,"elapsed":1136,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["### Problem Analysis:\n","The main issues with the new smartwatch are:\n","\n","- Lack of unique features compared to competitors, making it difficult to differentiate the product in the market.\n","- High price point that does not provide sufficient value to customers, leading to disappointing sales.\n","\n","### Strategic Recommendations:\n","\n","#### Suggestion for the product:\n","To address the issue of lacking unique features, we recommend the following:\n","\n","- Conduct market research to identify emerging trends and technologies in the smartwatch industry.\n","- Develop a minimum viable product (MVP) that incorporates a unique feature or functionality that sets the smartwatch apart from competitors.\n","- Consider partnering with a popular fitness or wellness brand to integrate their technology into the smartwatch, making it more appealing to customers.\n","- Offer customization options, such as interchangeable straps or watch faces, to give customers a sense of personalization and ownership.\n","\n","#### Suggestion for pricing:\n","To address the issue of a high price point, we recommend the following:\n","\n","- Conduct a price elasticity analysis to determine the optimal price point for the smartwatch.\n","- Consider offering a premium version of the smartwatch with additional features or a higher-end design, while keeping the base model at a more competitive price point.\n","- Offer discounts or promotions to incentivize customers to purchase the smartwatch, such as a \"buy one get one free\" deal or a limited-time discount.\n","- Consider a subscription-based model, where customers pay a monthly or annual fee for access to premium features or services.\n","\n","#### Suggestion for marketing communications:\n","To address the issue of disappointing sales, we recommend the following:\n","\n","- Develop a targeted marketing campaign that highlights the unique features and benefits of the smartwatch, such as its ability to track fitness metrics or receive notifications.\n","- Utilize social media platforms to engage with customers and gather feedback on the product, while also promoting the smartwatch through influencer partnerships and sponsored content.\n","- Create a series of educational videos or blog posts that demonstrate the features and benefits of the smartwatch, such as how to use the built-in GPS or how to customize the watch face.\n","- Offer a satisfaction guarantee or a warranty program to alleviate concerns about the product's quality and value.\n"]}]},{"cell_type":"markdown","source":["Explanation:\n","\n","- `<Instructions>`: Sets the model's persona and primary objective.\n","\n","- `<Article>`: Contains the raw data to be analyzed.\n","\n","- `<Response_Format>`: Clearly outlines the desired structure of the output. This forces the model to organize its response systematically and address all specified points.\n","\n"],"metadata":{"id":"BzHT8XuQ-5En"}},{"cell_type":"markdown","source":["## Structured Output"],"metadata":{"id":"1-MIkua_qMkJ"}},{"cell_type":"markdown","source":["`CSV` is best reserved for situations where the data is exclusively flat and **tabular**, like a basic spreadsheet.\n","\n","`JSON` is the clear winner for most tasks today because it can handle **hierarchical and nested data**. This is essential for working with APIs, configurations, and any data that isn't a simple table. It also natively supports data types like integers, strings, and booleans, which simplifies processing."],"metadata":{"id":"HJ40UxIZqQe9"}},{"cell_type":"markdown","source":["### Output : CSV"],"metadata":{"id":"eI45ATexGx3I"}},{"cell_type":"code","source":["# Example: Structured output (CSV)\n","prompt = \"\"\"You are a helpful assistant.\n","**Task:** Convert the following customer list into a CSV string.\n","**Output Format:** The first row should contain the headers \"Name\" and \"City\".\n","The subsequent rows should contain the customer data, with values separated by commas.\n","Whole answer should be under the backtrick ```csv ... ```.\n","Response the final answer only.\n","**Data:**\n","- John Doe from New York\n","- Jane Smith from London\n","- Peter Jones from Tokyo\n","\"\"\"\n","\n","ai_msg_csv = llm.invoke(prompt)\n","print(\"Structured Output:\\n\", ai_msg_csv.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1N_Awr4qPtT","outputId":"9d61bae9-5350-4f05-9562-857afcb6c5f9","executionInfo":{"status":"ok","timestamp":1770626970753,"user_tz":-420,"elapsed":265,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Structured Output:\n"," ```csv\n","Name,City\n","John Doe,New York\n","Jane Smith,London\n","Peter Jones,Tokyo\n","```\n"]}]},{"cell_type":"markdown","source":["#### Parsing CSV Output into a DataFrame"],"metadata":{"id":"snb2aS38F04e"}},{"cell_type":"markdown","source":["We used a regex pattern to find the ```csv``` content and convert them into a DataFrame."],"metadata":{"id":"Tpz49DBWF6Up"}},{"cell_type":"code","source":["import re\n","import pandas as pd\n","import io\n","\n","def csv_string_to_df(text: str) -> pd.DataFrame:\n","    \"\"\"\n","    Extracts CSV content from a string and converts it into a pandas DataFrame.\n","\n","    Args:\n","        text (str): The input string containing CSV content enclosed in ```csv...```.\n","\n","    Returns:\n","        pd.DataFrame: A pandas DataFrame containing the extracted data.\n","    \"\"\"\n","    # Use a regex pattern to find the content between the delimiters\n","    match = re.search(r'```csv\\s(.*?)```', text, re.DOTALL)\n","\n","    if match:\n","        # Extract the content from the first capturing group\n","        csv_content = match.group(1).strip()\n","\n","        # Use io.StringIO to treat the string as a file\n","        data = io.StringIO(csv_content)\n","\n","        # Read the \"file\" into a pandas DataFrame\n","        df = pd.read_csv(data)\n","\n","        return df\n","    else:\n","        # Return an empty DataFrame or raise an error if no match is found\n","        print(\"No CSV content found within ```csv...``` delimiters.\")\n","        return pd.DataFrame()"],"metadata":{"id":"9F0mecNaEi3f","executionInfo":{"status":"ok","timestamp":1770626979812,"user_tz":-420,"elapsed":334,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["csv_string_to_df(ai_msg_csv.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"rmEcEtk7GE8q","outputId":"905c31b0-4851-42fc-bb70-d8f45dee73ea","executionInfo":{"status":"ok","timestamp":1770626981842,"user_tz":-420,"elapsed":92,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          Name      City\n","0     John Doe  New York\n","1   Jane Smith    London\n","2  Peter Jones     Tokyo"],"text/html":["\n","  <div id=\"df-2ee211ca-cb27-4e11-b6b1-1882834b182c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>City</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>John Doe</td>\n","      <td>New York</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jane Smith</td>\n","      <td>London</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Peter Jones</td>\n","      <td>Tokyo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ee211ca-cb27-4e11-b6b1-1882834b182c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2ee211ca-cb27-4e11-b6b1-1882834b182c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2ee211ca-cb27-4e11-b6b1-1882834b182c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"csv_string_to_df(ai_msg_csv\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"John Doe\",\n          \"Jane Smith\",\n          \"Peter Jones\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"New York\",\n          \"London\",\n          \"Tokyo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["### Output : JSON"],"metadata":{"id":"qUqbr39-G8kl"}},{"cell_type":"code","source":["# Example: Structured output (JSON)\n","prompt = \"\"\"\n","You are a helpful assistant.\n","For the given student record, return a JSON object with the following fields:\n","- name (string) ‚Üí student‚Äôs full name\n","- age (integer) ‚Üí student‚Äôs age\n","- scores (object) ‚Üí nested dictionary with subject name as key and integer score as value\n","- extracurricular (array of strings) ‚Üí list of activities\n","The whole answer must be under ```json ... ```.\n","Student Record:\n","Alice, 21 years old. Math = 85, English = 92. She joined Basketball and Drama Club.\n","\n","Answer:\n","Response the final answer only.\n","\"\"\"\n","\n","ai_msg_json = llm.invoke(prompt)\n","print(\"Structured Output:\\n\", ai_msg_json.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a1fd0110-e8a1-4976-9bbd-9d309ec1d51d","id":"PkbM0hvuG8kl","executionInfo":{"status":"ok","timestamp":1770627089773,"user_tz":-420,"elapsed":314,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Structured Output:\n"," ```json\n","{\n","  \"name\": \"Alice\",\n","  \"age\": 21,\n","  \"scores\": {\n","    \"Math\": 85,\n","    \"English\": 92\n","  },\n","  \"extracurricular\": [\"Basketball\", \"Drama Club\"]\n","}\n","```\n"]}]},{"cell_type":"markdown","source":["#### Parsing JSON Output into Dict"],"metadata":{"id":"e6UZdGS6G8kl"}},{"cell_type":"markdown","source":["We used a regex pattern to find the ```csv``` content and convert them into a DataFrame."],"metadata":{"id":"pbYRVsTRG8kl"}},{"cell_type":"code","source":["import re\n","import json\n","\n","def json_string_to_dict(text: str):\n","    \"\"\"\n","    Extracts JSON content from a string enclosed in ```json...```\n","    and parses it into a Python dict or list.\n","\n","    Args:\n","        text (str): The input string containing JSON content enclosed in ```json...```.\n","\n","    Returns:\n","        dict or list: Parsed JSON object (Python dict or list).\n","    \"\"\"\n","    # Use regex to find JSON block\n","    match = re.search(r'```json\\s(.*?)```', text, re.DOTALL)\n","\n","    if match:\n","        # Extract JSON content\n","        json_content = match.group(1).strip()\n","\n","        try:\n","            return json.loads(json_content)\n","        except json.JSONDecodeError as e:\n","            print(\"Invalid JSON:\", e)\n","            return None\n","    else:\n","        print(\"No JSON content found within ```json...``` delimiters.\")\n","        return None"],"metadata":{"id":"mVl5noz0M8AX","executionInfo":{"status":"ok","timestamp":1770627095009,"user_tz":-420,"elapsed":2,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["dict_output = json_string_to_dict(ai_msg_json.content)\n","dict_output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUIY-djMM-P_","outputId":"4e0a75ae-baf4-446c-d190-20e245ba30d5","executionInfo":{"status":"ok","timestamp":1770627095893,"user_tz":-420,"elapsed":13,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'name': 'Alice',\n"," 'age': 21,\n"," 'scores': {'Math': 85, 'English': 92},\n"," 'extracurricular': ['Basketball', 'Drama Club']}"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["dict_output['scores']['Math']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KjqbbnvNeE4","outputId":"4a4c8898-dec7-406e-a29f-f166f0c34176","executionInfo":{"status":"ok","timestamp":1770627097541,"user_tz":-420,"elapsed":34,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["85"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["### Output : Pydantic Schema"],"metadata":{"id":"QR96B7zq0pfm"}},{"cell_type":"markdown","source":["- LangChain supports structured outputs, **allowing us to bind a schema (dict / JSON Schema / Pydantic) to the model**\n","  - and enforce responses to follow the defined structure instead of relying only on prompt wording.\n","- ***However, complex output structures may still fail, so prompting and custom parsing function are still important in some cases.***\n","\n","Read more: [LangChain Docs ‚Äì Structured Outputs](https://python.langchain.com/docs/concepts/structured_outputs/)\n"],"metadata":{"id":"V9xRrjgy09pD"}},{"cell_type":"code","source":["# pydantic schema\n","\n","# suppose that we want the output something like this :\n","'''{'name': 'Alice',\n"," 'age': 21,\n"," 'scores': {'Math': 85, 'English': 92},\n"," 'extracurricular': ['Basketball', 'Drama Club']}'''\n","\n","# we can defined class (data fields) like this\n","\n","from typing import Dict, List\n","from pydantic import BaseModel, Field\n","\n","class DesiredOutput(BaseModel):\n","    name: str = Field(description=\"Student's first name\")\n","    age: int = Field(description=\"Age in years\")\n","    extracurricular: List[str] = Field(description=\"List of activities/clubs\")\n","\n","    #subject_scores: Dict[str, int] = Field(description=\"Key = subject, Value = scores (as a JSON object)\")\n","\n","    # This line cause an error. / Complex Data Structure (uncomment if you want to test it)"],"metadata":{"id":"DLSKUOVy0uN2","executionInfo":{"status":"ok","timestamp":1770627105567,"user_tz":-420,"elapsed":56,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Wrap LLM so it returns a DesiredOutput object directly\n","structured_llm = llm.with_structured_output(DesiredOutput)"],"metadata":{"id":"LNMNByvN27fS","executionInfo":{"status":"ok","timestamp":1770627109337,"user_tz":-420,"elapsed":27,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["prompt = \"\"\"\n","You are a helpful assistant.\n","For the given student record, extract informations\n","\n","Student Record:\n","Alice, 21 years old. Math = 85, English = 92. She joined Basketball and Drama Club.\n","\n","Answer:\n","\"\"\"\n","\n","\n","# Generate output\n","results = structured_llm.invoke(prompt)\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJc0JMrS3pld","outputId":"7a69c48c-8f94-40cb-89d0-f851aa6a6cbe","executionInfo":{"status":"ok","timestamp":1770627112925,"user_tz":-420,"elapsed":375,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DesiredOutput(name='Alice', age=21, extracurricular=['Basketball', 'Drama Club'])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["results.model_dump_json()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"fqArflod__Q4","outputId":"6d943f74-e057-49f7-beb2-02df134445e9","executionInfo":{"status":"ok","timestamp":1770627115201,"user_tz":-420,"elapsed":17,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'{\"name\":\"Alice\",\"age\":21,\"extracurricular\":[\"Basketball\",\"Drama Club\"]}'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["## Boundary Condition\n","- **Don't know, don't guess**  \n","  Instruct the model to answer *\"I don‚Äôt know\"* if the information is unknown or unverifiable.  \n","  ‚Üí Helps prevent the model from attempting to answer overly difficult or specific open-ended questions.  \n","  > Note: This depends on the **use case** ‚Äî but in scenarios where we *don‚Äôt want the model to attempt an uncertain answer*, this condition is very useful.\n","\n","- **Output Format Remarking**  \n","  Explicitly remind the model about the required output format.  \n","  ‚Üí e.g., *\"Don‚Äôt give any additional explanation, just output [format] only.\"*"],"metadata":{"id":"3xeHCngFhtAK"}},{"cell_type":"code","source":["# Example 1: Without boundary condition\n","prompt = \"\"\"\n","What are the details of the announcement from the Meteorological Department, Announcement No. 2/2025, regarding ‚ÄòMeasures to Cope with the Early Arrival of Summer Storms‚Äô?\n","\"\"\"\n","\n","ai_msg = llm.invoke(prompt)\n","print(\"Without boundary condition:\\n\", ai_msg.content)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVMrB0dcd1ic","outputId":"f016de8d-0032-4359-a832-c7d7a6003939","executionInfo":{"status":"ok","timestamp":1770627119901,"user_tz":-420,"elapsed":231,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Without boundary condition:\n"," I'm unable to verify the details of the announcement from the Meteorological Department, Announcement No. 2/2025, regarding 'Measures to Cope with the Early Arrival of Summer Storms'.\n"]}]},{"cell_type":"markdown","source":["**Key Takeaways**:\n","- Without boundary conditions, an LLM will still attempt to generate an answer ‚Äî sometimes hallucinating content, and other times making an estimated guess while recognizing its own uncertainty.\n","- If you want to avoid such cases, define clear boundary conditions that tell the LLM to respond with `‚ÄúI don‚Äôt know‚Äù` or another `concise fallback` instead of producing uncertain or fabricated answers.\n","- This keeps your system consistent and predictable."],"metadata":{"id":"culOGTStHBct"}},{"cell_type":"code","source":["# Example 2: With boundary condition\n","prompt = \"\"\"\n","What are the details of the announcement from the Meteorological Department, Announcement No. 2/2025, regarding ‚ÄòMeasures to Cope with the Early Arrival of Summer Storms‚Äô?\n","\n","If the answer is not known or cannot be verified, just reply: `None`.\n","\"\"\"\n","\n","ai_msg = llm.invoke(prompt)\n","print(\"With boundary condition:\\n\", ai_msg.content)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zFYUTpPeyR4v","outputId":"4ffe1674-9a9f-479a-96a7-2524f1f9c397","executionInfo":{"status":"ok","timestamp":1770627148410,"user_tz":-420,"elapsed":257,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["With boundary condition:\n"," None.\n"]}]},{"cell_type":"markdown","source":["## Prompt Template\n","\n","Prompt templates offer several benefits:\n","\n","- **Consistency**: Ensure a consistent structure for your prompts across multiple interactions\n","- **Efficiency**: Easily swap out variable content without rewriting the entire prompt\n","- **Testability**: Quickly test different inputs and edge cases by changing only the variable portion\n","- **Scalability***: Simplify prompt management as your application grows in complexity\n","- **Version control**: Easily track changes to your prompt structure over time by keeping tabs only on the core part of your prompt, separate from dynamic inputs"],"metadata":{"id":"UyIZT0fiz-x9"}},{"cell_type":"markdown","source":["### Example: Prompt Template in a Loop (Task: Sentiment Analysis)\n","\n","Example Task: **Sentiment Analysis**\n","\n","We used a prompt template with the approach **‚Äúrun in a loop + change only variables‚Äù**.  \n","This demonstrates how prompt templates cover several benefits at once:\n","\n","- **Consistency**: Every iteration uses the same prompt structure.  \n","- **Efficiency**: Only the variable `{text}` changes in each loop.  \n","- **Testability**: Multiple inputs can be tested quickly by swapping variable values.  \n","- **Scalability**: The same template can be applied to a larger dataset without modification.  \n","- **Version Control**: Easily track prompt versions against results.\n","\n","\n"],"metadata":{"id":"3R-tfOsrRG7A"}},{"cell_type":"code","source":["!wget https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt"],"metadata":{"id":"4ryOL6guq0C-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5503a461-8a11-4b79-92e8-9c2e2ed2a7d3","executionInfo":{"status":"ok","timestamp":1770627185768,"user_tz":-420,"elapsed":553,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["--2026-02-09 08:53:05--  https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt\n","Resolving github.com (github.com)... 140.82.112.4\n","Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt [following]\n","--2026-02-09 08:53:06--  https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 122071 (119K) [text/plain]\n","Saving to: ‚Äòdev.txt‚Äô\n","\n","dev.txt             100%[===================>] 119.21K  --.-KB/s    in 0.02s   \n","\n","2026-02-09 08:53:06 (5.28 MB/s) - ‚Äòdev.txt‚Äô saved [122071/122071]\n","\n"]}]},{"cell_type":"code","source":["def read_xy_data(filename: str) -> tuple[list[str], list[int]]:\n","    x_data = []\n","    y_data = []\n","    with open(filename, 'r') as f:\n","        for line in f:\n","            label, text = line.strip().split(' ||| ')\n","            x_data.append(text)\n","            y_data.append(int(label))\n","    return x_data, y_data"],"metadata":{"id":"fXa_FpBL6zt2","executionInfo":{"status":"ok","timestamp":1770627188445,"user_tz":-420,"elapsed":19,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["x_test, y_test = read_xy_data('dev.txt')\n","x_test, y_test = x_test[:10], y_test[:10] # small size for quick testing"],"metadata":{"id":"IbNrlgaWRVz_","executionInfo":{"status":"ok","timestamp":1770627192564,"user_tz":-420,"elapsed":20,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["For sentiment analysis, we will be using the following prompt:\n","\n","```\n","Analyse the sentiment of the following text: ```text```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","```\n","LLMs nowaday usually have chain-of-thought baked in so they usually will output their reasoning before answering.\n","\n","- It is important to tell the model not to output their explanation by including `**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","`\n","- Otherwise, it will not be easy to programmatically use the outputs.\n","Alternatively, you can use structured outputs `(see table of contents -> Structured Output)` for ease of parsing."],"metadata":{"id":"6EU6prW_oeTF"}},{"cell_type":"code","source":["prompt_template = \"\"\"\n","Analyse the sentiment of the following text: ```{x_input}```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\"\"\""],"metadata":{"id":"y3wwc3vJiiJO","executionInfo":{"status":"ok","timestamp":1770627195344,"user_tz":-420,"elapsed":26,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["from tqdm.notebook import tqdm"],"metadata":{"id":"Py85PRxuXwjN","executionInfo":{"status":"ok","timestamp":1770627197044,"user_tz":-420,"elapsed":16,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["import time\n","from tqdm.notebook import tqdm\n","\n","output = []\n","for sent in tqdm(x_test):\n","   try:\n","      prompt_filled = prompt_template.format(x_input=sent)\n","      print('prompt:', prompt_filled) # debugging\n","      output_res = llm.invoke(prompt_filled).content.strip()\n","      print('response:', output_res) # debugging\n","      print('--'*20)\n","      output.append(int(output_res))\n","      time.sleep(2) # Adding a 2-second delay to avoid rate limit error\n","   except:\n","      output.append(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9b4f7e1961ba42df88814dda0b392320","990e58c5061f48a5839b27be1683137d","e3b61235ebcc4f1fbea597a5845e138f","4ccce19bc99d4cd18ce4e9a0f6b838be","ae155ca74bf24eb58e09bbd762d9d58f","9579b4aa97ba4c8fbf0cb7a2ad1f06f8","185000b1d0a541fea9a2fd9d154e10e5","4a37adc5b3f54dfd819866a7ac67969d","c5d7c4dc79054245834085755db937d0","1cbe04e520a6436db7b638c506acd0c9","314ee287411948e6a7e39be27d040006"]},"id":"QFFPVtwT9rjZ","outputId":"f950f53d-8cf1-419b-ed18-197386dfb82d","executionInfo":{"status":"ok","timestamp":1770627314319,"user_tz":-420,"elapsed":21147,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b4f7e1961ba42df88814dda0b392320"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["prompt: \n","Analyse the sentiment of the following text: ```It 's a lovely film with lovely performances by Buy and Accorsi .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```No one goes unindicted here , which is probably for the best .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```And if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```A warm , funny , engaging film .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Uses sharp humor and insight into human nature to examine class conflict , adolescent yearning , the roots of friendship and sexual identity .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Half Submarine flick , Half Ghost Story , All in one criminally neglected film```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Entertains by providing good , lively company .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Dazzles with its fully-written characters , its determined stylishness -LRB- which always relates to characters and story -RRB- and Johnny Dankworth 's best soundtrack in years .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Visually imaginative , thematically instructive and thoroughly delightful , it takes us on a roller-coaster ride from innocence to experience without even a hint of that typical kiddie-flick sentimentality .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n","prompt: \n","Analyse the sentiment of the following text: ```Nothing 's at stake , just a twisty double-cross you can smell a mile away -- still , the derivative Nine Queens is lots of fun .```\n","if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n","**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n","response: 1\n","----------------------------------------\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test, output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dp7ZS8hKVRb8","outputId":"60e05be1-8cab-49dc-c4ec-a118a22b9e09","executionInfo":{"status":"ok","timestamp":1770627318571,"user_tz":-420,"elapsed":1959,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["## Additional: Temperature Setting"],"metadata":{"id":"_AryYrz0F-Pr"}},{"cell_type":"markdown","source":["Settings to keep in mind\n","\n","- Temperature is an important parameter to consider.\n","  - Keep it low if you are looking for exact or deterministic answers.\n","  - Keep it high if you are looking for more diverse or creative responses.\n","\n","> In all the previous examples, we only set up the LLM once, and the parameter was fixed as Temperature = 0\n","\n","This means every example so far was generated with a deterministic setting (no randomness)."],"metadata":{"id":"oNWq0plMFcEV"}},{"cell_type":"markdown","source":["### Approach 1 : Gemini"],"metadata":{"id":"26-zG4kznPuU"}},{"cell_type":"markdown","source":["Temperature Range for Gemini-2.5-flash : 0-2 (default 1)\n","\n",">Ref: https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash"],"metadata":{"id":"mJA6w0hAdyxg"}},{"cell_type":"code","source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm_low_temp = ChatGoogleGenerativeAI(\n","    model=\"gemini-2.5-flash\",\n","    temperature=0,\n","    max_tokens=None,\n","    timeout=None,\n","    max_retries=2,\n","    # other params...\n",")"],"metadata":{"id":"1LscvX8fjVzY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm_high_temp = ChatGoogleGenerativeAI(\n","    model=\"gemini-2.5-flash\",\n","    temperature=2,\n","    max_tokens=None,\n","    timeout=None,\n","    max_retries=2,\n","    # other params...\n",")"],"metadata":{"id":"gx4NPLujeWZN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# llm_low_temp\n","prompt = \"Write one slogan for a mobile banking application. Just only answer the slogan without additional suggestions\"\n","for rnd in range(3):\n","  try:\n","    output_res = llm_low_temp.invoke(prompt).content.strip()\n","    print(f\"Round {rnd+1} | response:\", output_res)\n","  except Exception as e:\n","    print(f\"Round {rnd+1} | Error:\", e)\n","\n","  print(\"--\"*30)\n","  time.sleep(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kbra6aNZgtM3","outputId":"6cbab12d-63d3-4b43-a77b-5c7cd13b6b23","executionInfo":{"status":"ok","timestamp":1762917777550,"user_tz":-420,"elapsed":14454,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Round 1 | response: Your bank, always in reach.\n","------------------------------------------------------------\n","Round 2 | response: Your bank, always in reach.\n","------------------------------------------------------------\n","Round 3 | response: Your bank, always with you.\n","------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["# llm_high_temp\n","prompt = \"Write one slogan for a mobile banking application. Just only answer the slogan without additional suggestions\"\n","for rnd in range(3):\n","  try:\n","    output_res = llm_high_temp.invoke(prompt).content.strip()\n","    print(f\"Round {rnd+1} | response:\", output_res)\n","  except Exception as e:\n","    print(f\"Round {rnd+1} | Error:\", e)\n","\n","  print(\"--\"*30)\n","  time.sleep(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dAlpPN-nhd4w","outputId":"7725dece-0e55-46c8-8662-3b24a8544d80","executionInfo":{"status":"ok","timestamp":1762917800434,"user_tz":-420,"elapsed":13686,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Round 1 | response: Your Money, On Your Terms.\n","------------------------------------------------------------\n","Round 2 | response: Banking at Your Fingertips.\n","------------------------------------------------------------\n","Round 3 | response: Your bank, at your fingertips.\n","------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["### Approach 2 : Groq"],"metadata":{"id":"RsY7T_wVnVfO"}},{"cell_type":"code","source":["llm_low_temp = ChatGroq(\n","    model=\"llama-3.1-8b-instant\", # can change\n","    temperature=0,\n","    max_tokens=None,\n","    timeout=None,\n","    max_retries=2,\n",")"],"metadata":{"id":"wvmj7HNYnVfO","executionInfo":{"status":"ok","timestamp":1770627441386,"user_tz":-420,"elapsed":184,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["llm_high_temp = ChatGroq(\n","    model=\"llama-3.1-8b-instant\", # can change\n","    temperature=0.9,\n","    max_tokens=None,\n","    timeout=None,\n","    max_retries=2,\n",")"],"metadata":{"id":"Dl-SlB7anVfO","executionInfo":{"status":"ok","timestamp":1770627443678,"user_tz":-420,"elapsed":169,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# low_temp\n","prompt = \"Write one slogan for a mobile banking application. Just only answer the slogan without additional suggestions\"\n","for rnd in range(3):\n","  try:\n","    output_res = llm_low_temp.invoke(prompt).content.strip()\n","    print(f\"Round {rnd+1} | response:\", output_res)\n","  except Exception as e:\n","    print(f\"Round {rnd+1} | Error:\", e)\n","\n","  print(\"--\"*30)\n","  time.sleep(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"75cab8b6-9a07-4187-bc9c-18df72786776","executionInfo":{"status":"ok","timestamp":1770627556482,"user_tz":-420,"elapsed":6507,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}},"id":"1Z063qNdnVfP"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Round 1 | response: \"Bank on the go, wherever you grow.\"\n","------------------------------------------------------------\n","Round 2 | response: \"Bank on the go, wherever you grow.\"\n","------------------------------------------------------------\n","Round 3 | response: \"Bank on the go, wherever you grow.\"\n","------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["# llm_high_temp\n","prompt = \"Write one slogan for a mobile banking application. Just only answer the slogan without additional suggestions\"\n","for rnd in range(3):\n","  try:\n","    output_res = llm_high_temp.invoke(prompt).content.strip()\n","    print(f\"Round {rnd+1} | response:\", output_res)\n","  except Exception as e:\n","    print(f\"Round {rnd+1} | Error:\", e)\n","\n","  print(\"--\"*30)\n","  time.sleep(2) # Adding a 2-second delay to avoid rate limit error"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c8dad15-527a-4616-c882-eab8127ac174","executionInfo":{"status":"ok","timestamp":1770627564538,"user_tz":-420,"elapsed":6334,"user":{"displayName":"Prommin Vutivivatchai","userId":"09771428781838508672"}},"id":"gCvrrT8wnVfP"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Round 1 | response: \"Banking at Your Command\"\n","------------------------------------------------------------\n","Round 2 | response: \"Your wallet, at your fingertips.\"\n","------------------------------------------------------------\n","Round 3 | response: \"Bank on your terms, anywhere you are.\"\n","------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["Summary\n","\n","- Low temp ‚Üí Reliable, consistent outputs. Useful for classification, extraction, or when you want reproducibility.\n","- High temp ‚Üí Diverse, creative slogans. Useful for brainstorming, ideation, or when multiple fresh options are desired."],"metadata":{"id":"jp0VKZZVhzsD"}}]}